# Human-in-the-Loop (HITL) Philosophy

**Status**: Normative
**Version**: 1.0.0

At SWE AI Fleet, we believe **AI should be a force multiplier, not a replacement** for human judgment. Our architecture is designed around the concept of the **"Director Model"**, where the human developer transitions from being the primary writer of code to the director of a fleet of autonomous agents.

This document defines the principles and checkpoints where human interaction is mandatory or encouraged.

---

## 1. The Core Principle: Intent vs. Execution

| | Responsibility | Who |
|---|---|---|
| **The "Why"** | **Intent, Business Value, Ethical Constraints** | ðŸ‘¤ **Human** |
| **The "How"** | **Implementation, Boilerplate, Testing, Syntax** | ðŸ¤– **AI Fleet** |
| **The "What"** | **Verification, Approval, Deployment** | ðŸ‘¤ **Human** |

We do not aim for "Fully Autonomous" where the AI decides *what* to build. We aim for **"Autonomous Execution"** of human-defined intent.

---

## 2. The Four Gates of Control

The system is designed as a series of **Finite State Machines (FSMs)** with explicit gates where human approval is required to proceed. This prevents the "runaway AI" problem.

### ðŸšª Gate 1: The Product Definition (PO Review)
**Service**: `Planning Service`
**State**: `PO_REVIEW` â†’ `READY_FOR_PLANNING`

*   **Input**: A human (Product Owner) drafts a User Story.
*   **AI Action**: The **StoryCoach** agent analyzes the story for clarity, ambiguity, and completeness (INVEST criteria).
*   **The Loop**: The AI suggests improvements, but **CANNOT** move the story to "Ready" on its own.
*   **Human Action**: The PO must explicitly click **"Approve"** to confirm the requirements are correct.

### ðŸšª Gate 2: The Technical Plan (Architect Review)
**Service**: `Planning Service` / `Task Derivation`
**State**: `PLAN_REVIEW` â†’ `PLANNED`

*   **Input**: An approved User Story.
*   **AI Action**: The **Architect** agent generates a technical `Plan`, breaking the story into `Tasks` and defining the dependency graph.
*   **The Loop**: The AI proposes a strategy (e.g., "Use Strategy Pattern here", "Add new microservice there").
*   **Human Action**: The Technical Lead reviews the plan. They can edit the tasks, change dependencies, or reject the approach. Only a human can authorize the fleet to start coding.

### ðŸšª Gate 3: The Implementation (Code Review)
**Service**: `Workflow Service`
**State**: `CODE_REVIEW` â†’ `TESTING`

*   **Input**: Code generated by `Developer` agents.
*   **AI Action**: The **QA** agent runs tests and static analysis. The **Architect** agent reviews the code against the plan.
*   **The Loop**: Agents perform "Peer Review" among themselves (Deliberation).
*   **Human Action**: Ultimately, the code is presented as a **Pull Request**. A human developer must perform the final merge. The AI cannot merge code to `main` without human sign-off (enforced by CI/CD policies, though the fleet can prepare the PR).

### ðŸšª Gate 4: The Exception Handle (Manual Intervention)
**Service**: All
**State**: `FAILED` / `BLOCKED`

*   **Scenario**: An agent gets stuck (loops, recurring errors) or tools fail.
*   **AI Action**: The agent raises a `Blocker` flag or moves the task to `FAILED`.
*   **Human Action**: The human receives an alert. They can:
    1.  **Modify the Context**: Update the story or add hints.
    2.  **Fix the Code**: Manually intervene in the file system.
    3.  **Restart the Agent**: Clear the agent's memory and retry.

---

## 3. Role-Based Access Control (RBAC) as a Safety Net

We enforce HITL not just through UI, but through cryptographic and architectural constraints.

*   **Role Separation**: An AI Agent acts as a specific role (e.g., `ROLE_DEV`). It *cannot* perform actions reserved for `ROLE_ARCHITECT` or `ROLE_ADMIN`.
*   **Scope Limiting**: An agent working on "Frontend Story #123" is granted a **Prompt Scope** that allows access *only* to frontend repositories and relevant docs. It cannot read database secrets or backend infrastructure code unless explicitly granted.

## 4. Observability: The "Glass Box"

To be an effective Director, the human must see what the fleet is doing.

*   **Thinking Process**: We log the raw "Chain of Thought" (`<think>...</think>`) of every agent.
*   **Live Dashboard**: The Monitoring Service provides a real-time view of which agent is working on what task.
*   **Audit Trail**: Every decision (Story created, Plan approved, Code committed) is recorded in the Knowledge Graph (Neo4j) with the identity of the actor (Human or AI).

---

## 5. Summary

**SWE AI Fleet** is a tool for **augmented engineering**.

*   **Bad**: "AI, build me an app." (Vague, dangerous, low quality)
*   **Good**: "AI, here is the spec for the auth module. Propose a plan." -> Human Refines -> "Execute plan." -> Human Reviews. (Controlled, high quality, safe).

