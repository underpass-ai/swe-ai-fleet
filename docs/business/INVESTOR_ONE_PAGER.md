# üöÄ SWE AI Fleet - Investor One Pager

**The Local-First, Autonomous Software Engineering Platform**

> **Thesis**: Enterprise AI development is broken. Cloud dependencies are too expensive, unsafe, and unreliable. The future is **self-hosted, small-model fleets** powered by **Precision Context**.

---

## üí• The Problem
Enterprises want AI development, but face a trilemma:
1.  **Data Privacy**: Sending proprietary code to OpenAI/Anthropic is a compliance nightmare (GDPR, SOC2).
2.  **Economics**: Cloud AI costs scale linearly. A team of 10 devs generates ~1B tokens/month = **$10k-$30k/month** bill.
3.  **Quality**: Large Context Windows (100k tokens) are lazy. Dumping an entire repo makes models hallucinate.

## üí° Our Solution
**SWE AI Fleet** is an open-source, self-hostable platform that runs on your infrastructure (even consumer GPUs).

### 1. The Core Innovation: Precision Context
Instead of "RAG" (naive search), we use a **Decision-Centric Knowledge Graph**.
*   **Traditional**: Dump 50 files ‚Üí GPT-4 (Expensive, Slow, Confused).
*   **Ours**: Extract 30 relevant lines + 3 past decisions ‚Üí **Qwen 7B** (Cheap, Fast, Accurate).
*   **Result**: Small open-source models outperform GPT-4 because they have *better context*, not more parameters.

### 2. The "Director Model"
We don't replace developers. We turn them into **Directors**.
*   **Human**: Sets intent, reviews architecture, approves plans.
*   **AI Fleet**: A council of specialized agents (Architect, Dev, QA) deliberate, critique, and write the code.
*   **Outcome**: 10x productivity multiplier.

---

## üí∞ The Economics (Cloud vs. Local)

| Feature | Cloud AI (Copilot/Devin) | SWE AI Fleet (Local) |
| :--- | :--- | :--- |
| **Cost (10 Devs)** | ~$300,000 / year (OpEx) | ~$15,000 (One-time Hardware) |
| **Data Privacy** | Code leaves network ‚ùå | **Zero Exfiltration** ‚úÖ |
| **Vendor Lock-in** | High (OpenAI API) ‚ùå | **None** (Swap models freely) ‚úÖ |
| **Latency** | Seconds (Network) | **Milliseconds** (Local GPU) ‚úÖ |

**Payback Period**: Buying an RTX 3090 ($800) pays for itself in **2 weeks** of heavy AI usage compared to GPT-4 API costs.

---

## üìà Market & Traction
*   **Target**: Regulated Industries (Finance, Healthcare, Defense) who *cannot* use cloud AI.
*   **Status**: **Production Ready**. 6 Microservices, 90% Test Coverage, Proven on RTX 3090 hardware.
*   **Moat**: The **Context Graph**. While others compete on model size (race to the bottom), we compete on *context quality* (proprietary data structure).

## ü§ù The Ask
We are building the **industry standard** for on-premise AI development.
*   **Seeking**: Strategic partners for pilot deployments in regulated environments.
*   **Contact**: `contact@underpassai.com`

---
*Detailed Business Plan available upon request.*

