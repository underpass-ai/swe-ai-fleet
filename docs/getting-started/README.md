# Getting Started with SWE AI Fleet

**Last Updated:** 2025-11-07
**Status:** ‚úÖ Production-Ready
**Deployment Time:** ~10-15 minutes

---

## üéØ What is SWE AI Fleet?

SWE AI Fleet is a **production-ready AI software development platform** that orchestrates teams of AI agents to collaboratively develop software. It features:

### **Core Capabilities**

- **ü§ñ Multi-Agent Deliberation** - Teams of 3 agents collaborate with peer review
- **üîê 3-Level RBAC System** - Tool, Workflow, and Data access control
- **üìä FSM-Driven Workflows** - Story and Task lifecycle management
- **üß† Precision Context** - Knowledge graph-powered surgical context (200 tokens vs 100K)
- **‚ö° GPU-Accelerated** - Ray + vLLM (self-hosted, 7B-13B models)
- **üèóÔ∏è Hexagonal Architecture** - DDD + Ports & Adapters (all 6 services)
- **üîç Full Observability** - Complete LLM reasoning visible

### **Why SWE AI Fleet?**

‚úÖ **100% Self-Hostable** - No cloud AI dependencies
‚úÖ **Data Sovereignty** - Code never leaves your network
‚úÖ **Small Models Work** - 7B-13B models perform like GPT-4 (precision context)
‚úÖ **Predictable Costs** - Add GPUs (CapEx) not API calls (OpEx)
‚úÖ **Production-Ready** - 1,265 tests, 90% coverage, clean architecture

---

## üöÄ Quick Start (10 Minutes)

### Prerequisites

**Required:**
- Kubernetes cluster (1.28+)
- kubectl configured to cluster
- Podman (for building images)
- Registry accessible (registry.underpassai.com or local)

**Optional (for GPU agents):**
- NVIDIA GPU (RTX 3090/4090)
- GPU operator installed
- Ray cluster

**Verify prerequisites:**
```bash
cd scripts/infra
./00-verify-prerequisites.sh
```

---

### Deploy to Kubernetes

```bash
# 1. Clone repository
git clone https://github.com/underpass-ai/swe-ai-fleet
cd swe-ai-fleet

# 2. Verify prerequisites
./scripts/infra/00-verify-prerequisites.sh

# 3. Deploy all services (first time: reset NATS streams)
cd scripts/infra
./fresh-redeploy.sh --reset-nats

# 4. Verify health
./verify-health.sh
```

**Expected output:**
```
‚úì orchestrator built
‚úì context built
‚úì planning built
‚úì workflow built
‚úì ray-executor built
‚úì monitoring built

‚úì All images pushed to registry

‚úì orchestrator is ready
‚úì context is ready
‚úì planning is ready
‚úì workflow is ready
‚úì ray-executor is ready
‚úì monitoring-dashboard is ready

‚úì All pods are running!
```

**Duration:** ~10-15 minutes (first time with --reset-nats)

---

## üèóÔ∏è What Gets Deployed

### **6 Microservices**

| Service | Port | Purpose | Status |
|---------|------|---------|--------|
| **Orchestrator** | 50055 | Multi-agent deliberation | ‚úÖ Running |
| **Context** | 50054 | Knowledge graph context | ‚úÖ Running |
| **Planning** | 50051 | Story FSM & lifecycle | ‚úÖ Running |
| **Workflow** | 50056 | Task FSM + RBAC L2 | ‚úÖ Running |
| **Ray Executor** | 50057 | GPU agent execution | ‚úÖ Running |
| **Monitoring** | 8080 | System health dashboard | ‚úÖ Running |

### **Infrastructure**

- NATS JetStream (messaging backbone)
- Neo4j (knowledge graph)
- Valkey (cache)

### **NATS Streams Created**

- `PLANNING_EVENTS` - Story state transitions
- `AGENT_WORK` - Agent execution results
- `WORKFLOW_EVENTS` - Task workflow events
- `CONTEXT_EVENTS` - Context updates

---

## üîç Verify Deployment

### Check All Services

```bash
cd scripts/infra
./verify-health.sh
```

**Expected:**
```
‚úì NATS:         Running (1/1)
‚úì Orchestrator: Running (1/1)
‚úì Context:      Running (2/2)
‚úì Planning:     Running (2/2)
‚úì Workflow:     Running (2/2)
‚úì Ray-Executor: Running (1/1)
‚úì Monitoring:   Running (1/1)
```

### Check Specific Service

```bash
# View pods
kubectl get pods -n swe-ai-fleet -l app=workflow

# View logs
kubectl logs -n swe-ai-fleet -l app=workflow --tail=50

# Follow logs (live)
kubectl logs -n swe-ai-fleet -l app=workflow -f
```

### Test gRPC APIs

```bash
# Port-forward Workflow Service
kubectl port-forward -n swe-ai-fleet svc/workflow 50056:50056

# Use grpcurl (install: go install github.com/fullstorydev/grpcurl/cmd/grpcurl@latest)
grpcurl -plaintext localhost:50056 list
grpcurl -plaintext localhost:50056 fleet.workflow.v1.WorkflowOrchestrationService/GetWorkflowState
```

---

## üåê Access Services

### Internal Access (within cluster)

Services are available via ClusterIP DNS:

```
orchestrator.swe-ai-fleet.svc.cluster.local:50055
context.swe-ai-fleet.svc.cluster.local:50054
planning.swe-ai-fleet.svc.cluster.local:50051
workflow.swe-ai-fleet.svc.cluster.local:50056
ray-executor.swe-ai-fleet.svc.cluster.local:50057
monitoring.swe-ai-fleet.svc.cluster.local:8080
nats.swe-ai-fleet.svc.cluster.local:4222
```

### External Access (optional)

**Monitoring Dashboard:**
```bash
# Port-forward
kubectl port-forward -n swe-ai-fleet svc/monitoring-dashboard 8080:8080

# Access: http://localhost:8080
```

**Or configure Ingress:**
- Edit `deploy/k8s/13-monitoring-dashboard.yaml`
- Add Ingress resource with your domain

**Ray Dashboard** (if RayCluster deployed):
```bash
./scripts/infra/07-expose-ray-dashboard.sh
# Access: https://ray.underpassai.com
```

---

## üîÑ After Code Changes

### Redeploy Services

```bash
cd scripts/infra

# Standard redeploy (keeps NATS streams)
./fresh-redeploy.sh

# With NATS stream reset (clean slate)
./fresh-redeploy.sh --reset-nats

# Skip build (only redeploy, faster)
./fresh-redeploy.sh --skip-build
```

**Duration:**
- Full rebuild: ~10-12 minutes
- Skip build: ~2-3 minutes

### View Rollout Status

```bash
# Watch deployment
kubectl rollout status deployment/workflow -n swe-ai-fleet

# Watch all pods
kubectl get pods -n swe-ai-fleet -w
```

---

## üÜò Troubleshooting

### Issue: CrashLoopBackOff

**Diagnosis:**
```bash
# Get pod name
POD=$(kubectl get pod -n swe-ai-fleet -l app=workflow -o jsonpath='{.items[0].metadata.name}')

# Check logs
kubectl logs -n swe-ai-fleet $POD --tail=100

# Check previous container (if crashed)
kubectl logs -n swe-ai-fleet $POD --previous

# Check events
kubectl describe pod -n swe-ai-fleet $POD | grep -A10 Events
```

**Common causes:**
- NATS not ready ‚Üí Wait for `nats-0` pod
- Missing ConfigMap ‚Üí `kubectl get cm -n swe-ai-fleet`
- Import errors ‚Üí Check logs for ModuleNotFoundError
- Consumer conflicts ‚Üí Run `./fresh-redeploy.sh` again

### Issue: ImagePullBackOff

**Diagnosis:**
```bash
# Check image exists
kubectl describe pod -n swe-ai-fleet $POD | grep "Failed to pull image"
```

**Fix:**
```bash
cd scripts/infra
./fresh-redeploy.sh  # Rebuilds and pushes images
```

### Issue: Service Not Receiving NATS Messages

**Diagnosis:**
```bash
# Check consumer status
kubectl exec -n swe-ai-fleet nats-0 -- nats consumer ls WORKFLOW_EVENTS

# Check service logs
kubectl logs -n swe-ai-fleet -l app=workflow | grep "subscribe\|consumer"

# Publish test message
kubectl exec -n swe-ai-fleet nats-0 -- \
  nats pub workflow.task.assigned '{"task_id":"test-001"}'

# Check if received
kubectl logs -n swe-ai-fleet -l app=workflow --since=10s | grep "test-001"
```

**Fix:**
```bash
cd scripts/infra
./fresh-redeploy.sh --reset-nats  # Reset NATS streams
```

---

## üìö Next Steps

### 1. Understand the Architecture

- [Microservices Architecture](../architecture/MICROSERVICES_ARCHITECTURE.md) - System design
- [RBAC System](../architecture/RBAC_REAL_WORLD_TEAM_MODEL.md) - 3-level access control
- [Hexagonal Architecture](../normative/HEXAGONAL_ARCHITECTURE_PRINCIPLES.md) - Design principles

### 2. Explore the System

```bash
# View all resources
kubectl get all -n swe-ai-fleet

# Monitor NATS streams
kubectl exec -n swe-ai-fleet nats-0 -- nats stream ls

# Check Neo4j
kubectl exec -n swe-ai-fleet neo4j-0 -- cypher-shell -u neo4j -p password "MATCH (n) RETURN count(n)"

# Check Valkey
kubectl exec -n swe-ai-fleet valkey-0 -- valkey-cli DBSIZE
```

### 3. Run Example Workflows

**Create a story:**
```bash
# Port-forward Planning Service
kubectl port-forward -n swe-ai-fleet svc/planning 50051:50051

# Use grpcurl
grpcurl -plaintext -d '{
  "brief": "Implement user authentication",
  "title": "As a user, I want to log in securely"
}' localhost:50051 fleet.planning.v1.PlanningService/CreateStory
```

**Check workflow status:**
```bash
# Port-forward Workflow Service
kubectl port-forward -n swe-ai-fleet svc/workflow 50056:50056

# Query workflow state
grpcurl -plaintext -d '{"task_id": "task-123"}' \
  localhost:50056 fleet.workflow.v1.WorkflowOrchestrationService/GetWorkflowState
```

### 4. Monitor System Health

```bash
# Access Monitoring Dashboard
kubectl port-forward -n swe-ai-fleet svc/monitoring-dashboard 8080:8080

# Open in browser: http://localhost:8080
```

---

## üõ†Ô∏è Development Workflow

### Make Code Changes

```bash
# 1. Create feature branch
git checkout -b feature/my-feature

# 2. Make changes to services/workflow/ (for example)
# ... edit code ...

# 3. Run tests
make test-unit

# 4. Deploy to cluster
cd scripts/infra
./fresh-redeploy.sh

# 5. Verify
./verify-health.sh
kubectl logs -n swe-ai-fleet -l app=workflow --tail=50
```

### Run Tests Locally

```bash
# Unit tests (~20s)
make test-unit

# Integration tests (~45s)
make test-integration

# E2E tests (~3-5min, requires cluster)
make test-e2e

# All tests
make test-all
```

---

## üîó Important Links

### Documentation
- [Architecture Overview](../architecture/MICROSERVICES_ARCHITECTURE.md)
- [Deployment Guide](../operations/DEPLOYMENT.md)
- [Roadmap](../../ROADMAP.md)
- [Testing Strategy](../TESTING_ARCHITECTURE.md)

### Operations
- [Troubleshooting](../operations/K8S_TROUBLESHOOTING.md)
- [Monitoring Setup](../monitoring/OBSERVABILITY_SETUP.md)

### Development
- [Contributing Guide](../development/CONTRIBUTING.md)
- [Git Workflow](../GIT_WORKFLOW.md)

---

## üìä System Requirements

### Minimum (Development)

- **Kubernetes:** 1.28+ (K3s, kind, minikube OK)
- **CPU:** 4 cores
- **Memory:** 16GB RAM
- **Storage:** 50GB SSD

**Services run, but agents will be mock** (no GPU)

### Recommended (Production)

- **Kubernetes:** 1.28+ (production cluster)
- **CPU:** 32 cores
- **Memory:** 128GB RAM
- **GPU:** 4√ó NVIDIA RTX 3090/4090 (24GB each)
- **Storage:** 500GB SSD

**Full agent execution with deliberation**

### For Detailed Requirements

See [prerequisites.md](prerequisites.md)

---

## üéì Learning Path

### Day 1: Deployment & Basics
1. Deploy system (`fresh-redeploy.sh --reset-nats`)
2. Verify health (`verify-health.sh`)
3. Explore monitoring dashboard
4. Read [MICROSERVICES_ARCHITECTURE.md](../architecture/MICROSERVICES_ARCHITECTURE.md)

### Day 2: Architecture Deep-Dive
1. Study [Hexagonal Architecture](../normative/HEXAGONAL_ARCHITECTURE_PRINCIPLES.md)
2. Read [RBAC Strategy](../architecture/RBAC_REAL_WORLD_TEAM_MODEL.md)
3. Explore codebase (start with Workflow Service)
4. Run tests (`make test-unit`)

### Day 3: Development
1. Create feature branch
2. Modify a service (add feature)
3. Write tests
4. Deploy to cluster
5. Verify functionality

---

## üÜò Need Help?

### Common Issues

**"Pods in CrashLoopBackOff"**
‚Üí Check logs: `kubectl logs -n swe-ai-fleet -l app=<service> --tail=100`

**"ImagePullBackOff"**
‚Üí Rebuild: `cd scripts/infra && ./fresh-redeploy.sh`

**"consumer is already bound"**
‚Üí Reset: `./fresh-redeploy.sh --reset-nats`

**"Tests failing"**
‚Üí See which service: `make test-unit` (shows failed services)

### Support Channels

- **Documentation:** [docs/](../)
- **Issues:** [GitHub Issues](https://github.com/underpass-ai/swe-ai-fleet/issues)
- **Email:** contact@underpassai.com

---

## üìù Configuration

### Change Registry

Edit `scripts/infra/fresh-redeploy.sh`:
```bash
REGISTRY="your-registry.com/swe-ai-fleet"
```

### Adjust Resources

Edit K8s manifests in `deploy/k8s/`:
```yaml
# Example: deploy/k8s/15-workflow-service.yaml
resources:
  requests:
    memory: "1Gi"    # Increase if needed
    cpu: "500m"
  limits:
    memory: "2Gi"
    cpu: "1000m"
```

Then redeploy:
```bash
cd scripts/infra && ./fresh-redeploy.sh
```

### Change Replica Counts

Edit K8s manifests:
```yaml
spec:
  replicas: 3  # Increase for high availability
```

Workflow and Planning support multiple replicas (NATS PULL consumers).

---

## üéØ What's Next?

After successful deployment:

1. ‚úÖ **Explore Services**
   - Try gRPC APIs (grpcurl)
   - Monitor NATS streams
   - Query Neo4j graph

2. ‚úÖ **Read Documentation**
   - [MICROSERVICES_ARCHITECTURE.md](../architecture/MICROSERVICES_ARCHITECTURE.md)
   - [RBAC_REAL_WORLD_TEAM_MODEL.md](../architecture/RBAC_REAL_WORLD_TEAM_MODEL.md)
   - [DEPLOYMENT.md](../operations/DEPLOYMENT.md)

3. ‚úÖ **Run Example Workflows**
   - Create story (Planning Service)
   - Monitor workflow (Workflow Service)
   - Execute agent tasks (Orchestrator)

4. ‚úÖ **Contribute**
   - Pick an issue
   - Create feature branch
   - Submit PR

---

## üèÜ Production Checklist

Before going to production:

- [ ] All 6 services deployed and healthy
- [ ] NATS streams initialized
- [ ] Neo4j persistence working
- [ ] Valkey cache working
- [ ] Tests passing (make test-unit)
- [ ] Monitoring dashboard accessible
- [ ] Logs structured and queryable
- [ ] Resource limits configured
- [ ] Backup strategy defined
- [ ] Runbooks created

---

## üìä System Status (Nov 7, 2025)

**Deployment Status:** ‚úÖ **Production-Ready**

| Component | Status | Tests | Coverage |
|-----------|--------|-------|----------|
| Orchestrator | ‚úÖ Production | 142 | 65% |
| Context | ‚úÖ Production | - | 96% |
| Planning | ‚úÖ Production | 278 | 95% |
| Workflow | ‚úÖ Ready | 138 | 94% |
| Ray Executor | ‚úÖ Production | - | 90% |
| Monitoring | ‚úÖ Production | 305 | 98% |
| **TOTAL** | **‚úÖ Ready** | **1,265** | **90%** |

**RBAC Status:**
- Level 1 (Tool Access): ‚úÖ Production
- Level 2 (Workflow Actions): ‚úÖ Production-Ready
- Level 3 (Data Access): ‚è≥ Next Sprint

**Infrastructure:** NATS, Neo4j, Valkey all production-ready

---

## üîó Related Documentation

- **[Deployment Guide](../operations/DEPLOYMENT.md)** - Operations procedures
- **[Architecture](../architecture/MICROSERVICES_ARCHITECTURE.md)** - System design
- **[Roadmap](../../ROADMAP.md)** - Project timeline
- **[Troubleshooting](../operations/K8S_TROUBLESHOOTING.md)** - Issue resolution

---

**Maintained by:** Tirso Garc√≠a Ib√°√±ez
**Review Frequency:** After each major deployment
**Next Update:** After RBAC L3 implementation
