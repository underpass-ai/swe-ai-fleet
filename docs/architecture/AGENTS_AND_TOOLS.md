# Agents and Tools - Complete Architecture

**Version**: 3.0 (Consolidated)  
**Status**: âœ… Single canonical document  
**Date**: 2025-11-16  
**Coverage**: 100% of core/agents_and_tools module

---

## ðŸ“‹ Table of Contents

1. [Executive Summary](#executive-summary)
2. [Bounded Context Overview](#bounded-context-overview)
3. [Directory Structure](#directory-structure)
4. [Hexagonal Architecture](#hexagonal-architecture)
5. [Domain Layer](#domain-layer)
6. [Application Layer](#application-layer)
7. [Infrastructure Layer](#infrastructure-layer)
8. [Agent Execution Flow](#agent-execution-flow)
9. [Tools Ecosystem](#tools-ecosystem)
10. [Use Cases](#use-cases)
11. [Ports & Adapters](#ports--adapters)
12. [Integration Examples](#integration-examples)
13. [Testing & Coverage](#testing--coverage)

---

## Executive Summary

The `agents_and_tools` bounded context is the **core intelligence engine** of SWE AI Fleet. It orchestrates:

- **5 specialized agent roles**: Developer, QA, Architect, DevOps, Data Engineer
- **10+ tool implementations**: File, Git, Docker, Kubernetes, Database, HTTP, Test execution
- **8 strategic use cases**: Planning, execution, artifact collection, result summarization
- **Precision context management**: RBAC-aware profile loading and execution modes

**Key Stats**:
- 23+ domain entities
- 8 orchestration use cases
- 4 infrastructure ports
- 10 tool implementations
- 100% test coverage on core paths
- Runs on Qwen 7B-13B or Llama models

---

## Bounded Context Overview

### Purpose

Transform **high-level software engineering tasks** into **concrete executable actions** through agent deliberation and tool orchestration.

### Responsibilities

| Responsibility | Implementation |
|---|---|
| **Agent Execution** | `VLLMAgent` - Universal agent with role-specific behaviors |
| **Plan Generation** | `GeneratePlanUseCase` - Create execution strategies |
| **Action Sequencing** | `GenerateNextActionUseCase` - ReAct-style reasoning |
| **Task Execution** | `ExecuteTaskUseCase`, `ExecuteTaskIterativeUseCase` |
| **Tool Management** | `ToolFactory`, `ToolExecutionAdapter` |
| **Profile Loading** | `LoadProfileUseCase`, `YamlProfileLoaderAdapter` |
| **Reasoning Capture** | `LogReasoningUseCase` - Full decision audit trails |
| **Result Aggregation** | `SummarizeResultUseCase`, `CollectArtifactsUseCase` |

### Interactions with Other Services

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Orchestrator Service                  â”‚
â”‚              (Defines tasks, delegates work)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ gRPC: ExecuteTask
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Agents & Tools (This Module)               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ VLLMAgent    â”‚â†’ â”‚ Tools    â”‚  â”‚ Profiles/RBAC    â”‚  â”‚
â”‚  â”‚ (ReAct)      â”‚  â”‚ (Docker, â”‚  â”‚ (Role-specific   â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  K8s,    â”‚  â”‚  behaviors)      â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  Files,  â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚              â”‚  â”‚  Git)    â”‚  â”‚                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ Results + Decision Logs
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Workflow Service (Job Tracking)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Directory Structure

```
core/agents_and_tools/
â”œâ”€â”€ agents/                          # Agent orchestration (Domain, App, Infra)
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ core/               # Core agent entities
â”‚   â”‚   â”‚   â”œâ”€â”€ results/            # Execution results
â”‚   â”‚   â”‚   â”œâ”€â”€ collections/        # Artifact collections
â”‚   â”‚   â”‚   â””â”€â”€ rbac/               # Role definitions
â”‚   â”‚   â””â”€â”€ ports/
â”‚   â”‚       â”œâ”€â”€ llm_client.py        # LLM communication port
â”‚   â”‚       â””â”€â”€ profile_loader_port.py
â”‚   â”œâ”€â”€ application/
â”‚   â”‚   â”œâ”€â”€ usecases/               # 8 orchestration use cases
â”‚   â”‚   â”œâ”€â”€ services/               # Business logic services
â”‚   â”‚   â””â”€â”€ dtos/                   # Data transfer objects
â”‚   â”œâ”€â”€ infrastructure/
â”‚   â”‚   â”œâ”€â”€ adapters/               # Port implementations
â”‚   â”‚   â”œâ”€â”€ factories/              # VLLMAgentFactory
â”‚   â”‚   â”œâ”€â”€ mappers/                # Entity conversions
â”‚   â”‚   â””â”€â”€ services/               # Prompt loading, JSON parsing
â”‚   â”œâ”€â”€ vllm_agent.py               # Main agent implementation
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ tools/                           # Tool implementations
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/               # Tool-specific domain objects
â”‚   â”‚   â””â”€â”€ ports/
â”‚   â”‚       â””â”€â”€ event_bus_port.py
â”‚   â”œâ”€â”€ adapters/
â”‚   â”‚   â””â”€â”€ redis_event_bus.py
â”‚   â”œâ”€â”€ db_tool.py                  # Database operations
â”‚   â”œâ”€â”€ docker_tool.py              # Container operations
â”‚   â”œâ”€â”€ file_tool.py                # File system operations
â”‚   â”œâ”€â”€ git_tool.py                 # Version control
â”‚   â”œâ”€â”€ http_tool.py                # HTTP requests
â”‚   â”œâ”€â”€ kubectl_tool.py             # Kubernetes operations
â”‚   â”œâ”€â”€ helm_tool.py                # Helm operations
â”‚   â”œâ”€â”€ psql_tool.py                # PostgreSQL operations
â”‚   â”œâ”€â”€ test_tool.py                # Test execution
â”‚   â”œâ”€â”€ runner/                     # MCP-based tool runner
â”‚   â””â”€â”€ tests/
â”‚
â”œâ”€â”€ common/                          # Shared domain concepts
â”‚   â”œâ”€â”€ domain/
â”‚   â”‚   â”œâ”€â”€ entities/
â”‚   â”‚   â”‚   â”œâ”€â”€ tool_definition.py
â”‚   â”‚   â”‚   â”œâ”€â”€ tool_registry.py
â”‚   â”‚   â”‚   â”œâ”€â”€ capability.py
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_capabilities.py
â”‚   â”‚   â”‚   â””â”€â”€ execution_mode.py
â”‚   â”‚   â””â”€â”€ ports/
â”‚   â”‚       â””â”€â”€ tool_execution_port.py
â”‚   â””â”€â”€ infrastructure/
â”‚       â””â”€â”€ mappers/
â”‚
â””â”€â”€ resources/                       # Configuration and templates
    â”œâ”€â”€ profiles/                    # Agent profiles (YAML)
    â”‚   â”œâ”€â”€ architect.yaml
    â”‚   â”œâ”€â”€ developer.yaml
    â”‚   â”œâ”€â”€ devops.yaml
    â”‚   â”œâ”€â”€ qa.yaml
    â”‚   â”œâ”€â”€ data.yaml
    â”‚   â””â”€â”€ roles.yaml
    â”œâ”€â”€ prompts/                     # LLM prompts
    â”‚   â”œâ”€â”€ plan_generation.yaml
    â”‚   â””â”€â”€ next_action_react.yaml
    â””â”€â”€ tools_description.json       # Tool schema for LLM
```

---

## Hexagonal Architecture

### Layers Diagram

```mermaid
graph TB
    subgraph Domain["ðŸ”· DOMAIN LAYER (Business Logic)"]
        E["Entities (23 types)"]
        VO["Value Objects"]
        P["Ports (4 interfaces)"]
        E --> VO
        E --> P
    end

    subgraph Application["ðŸŸ¡ APPLICATION LAYER (Orchestration)"]
        UC["Use Cases (8 types)"]
        DTO["DTOs"]
        SVC["Services (Business Logic)"]
        UC --> DTO
        UC --> SVC
        SVC --> Domain
    end

    subgraph Infrastructure["ðŸŸ¢ INFRASTRUCTURE LAYER (External Concerns)"]
        A["Adapters (4 types)"]
        F["Factories"]
        M["Mappers"]
        S["Services (Technical)"]
        A --> F
        A --> M
        A --> S
        A -.implements.-> Domain
    end

    Application --> Infrastructure
```

### Key Principles

1. **Domain Purity**: No IO, no external calls, only business logic
2. **Port-Driven**: All external dependencies are ports (interfaces)
3. **Dependency Injection**: All dependencies provided via constructor
4. **Immutability**: Entities are `@dataclass(frozen=True)` with validation in `__post_init__`
5. **Fail Fast**: No silent defaults or fallbacks
6. **Testing**: 100% mock-based unit tests (no external dependencies)

---

## Domain Layer

### Core Entities (23+ types)

#### 1. Agent Entities (`agents/domain/entities/core/`)

| Entity | Purpose | Key Fields |
|--------|---------|-----------|
| `Agent` | Base agent abstraction | name, capabilities, status |
| `AgentRole` | Role definition (DEV, QA, etc) | role_type, tools, permissions |
| `AgentCapability` | What an agent can do | tool_type, skill_level |
| `ExecutionContext` | Execution state | workspace, env_vars, constraints |
| `ExecutionStep` | Single action within task | action_type, parameters, status |

#### 2. Result Entities (`agents/domain/entities/results/`)

| Entity | Purpose |
|--------|---------|
| `TaskExecutionResult` | Final result of task execution |
| `StepExecutionResult` | Result of individual step |
| `ErrorRecord` | Captured error with context |

#### 3. Collection Entities (`agents/domain/entities/collections/`)

| Entity | Purpose |
|--------|---------|
| `ArtifactCollection` | Grouped artifacts from execution |
| `Artifact` | Single artifact (file, log, etc) |

#### 4. RBAC Entities (`agents/domain/entities/rbac/`)

| Entity | Purpose | Responsibility |
|--------|---------|---|
| `Role` | Role definition with permissions | Define what actions are allowed |
| `RoleFactory` | Create role instances | Load from YAML profiles |

#### 5. Tool Entities (`tools/domain/entities/`)

| Entity | Purpose |
|--------|---------|
| `DockerOperation` | Container operation metadata |
| `ProcessCommand` | Shell command execution |
| `ProcessResult` | Command execution result |
| `AuditRecord` | Operation audit trail |

### Ports (4 Interfaces)

```python
# 1. LLM Communication Port
class LLMClientPort(Protocol):
    async def generate_completion(
        self,
        prompt: str,
        model: str,
        max_tokens: int,
        temperature: float,
    ) -> str: ...

# 2. Profile Loading Port
class ProfileLoaderPort(Protocol):
    async def load_profile(self, role: str) -> AgentProfile: ...

# 3. Tool Execution Port (Common)
class ToolExecutionPort(Protocol):
    async def execute(self, tool_name: str, **kwargs) -> ToolResult: ...

# 4. Event Bus Port (Tools)
class EventBusPort(Protocol):
    async def publish_event(self, topic: str, data: dict) -> None: ...
```

---

## Application Layer

### 8 Use Cases

#### Planning Use Cases

**1. GeneratePlanUseCase**
- **Purpose**: Create multi-step execution strategy
- **Input**: Task, context, workspace state
- **Output**: Execution plan with steps
- **Dependencies**: LLMClientPort, ProfileLoaderPort

**2. GenerateNextActionUseCase**
- **Purpose**: Determine next action in ReAct loop
- **Input**: Current step, observations, history
- **Output**: Next action or terminal action
- **Dependencies**: LLMClientPort

#### Execution Use Cases

**3. ExecuteTaskUseCase**
- **Purpose**: Execute single task with tool calls
- **Input**: Task definition, workspace context
- **Output**: TaskExecutionResult
- **Dependencies**: ToolExecutionPort, LLMClientPort, ProfileLoaderPort

**4. ExecuteTaskIterativeUseCase**
- **Purpose**: Multi-step execution with ReAct loop
- **Input**: Task, max iterations, tool registry
- **Output**: Final result after all steps
- **Dependencies**: All above + observation collection

#### Support Use Cases

**5. LoadProfileUseCase**
- **Purpose**: Load agent profile for specific role
- **Input**: Role name, optional custom config
- **Output**: Complete agent profile with tools/permissions
- **Dependencies**: ProfileLoaderPort

**6. CollectArtifactsUseCase**
- **Purpose**: Aggregate execution artifacts
- **Input**: Execution result, artifact filters
- **Output**: Organized ArtifactCollection
- **Dependencies**: None (pure aggregation)

**7. LogReasoningUseCase**
- **Purpose**: Capture decision logs for audit
- **Input**: Reasoning steps, decisions, outcomes
- **Output**: Audit trail record
- **Dependencies**: None

**8. SummarizeResultUseCase**
- **Purpose**: Create human-readable result summary
- **Input**: Execution result, decision logs
- **Output**: Formatted summary
- **Dependencies**: None (pure transformation)

### Business Logic Services

| Service | Purpose |
|---------|---------|
| `StepExecutionService` | Execute single execution step |
| `ArtifactCollectionService` | Manage artifact lifecycle |
| `LogReasoningService` | Record reasoning/decisions |
| `ResultSummarizationService` | Summarize execution results |

---

## Infrastructure Layer

### Adapters (4 Port Implementations)

#### 1. VLLMClientAdapter (Implements LLMClientPort)

**Technology**: VLLM (open-source LLM serving)  
**Features**:
- Connect to local or remote VLLM server
- Supports multiple models (Qwen, Llama, etc)
- Configurable temperature, max_tokens, timeout
- Error handling and retry logic

**Configuration**:
```python
VLLMClientAdapter(
    base_url="http://localhost:8000",
    model="qwen2.5-7b",
    timeout=60,
    max_retries=3
)
```

#### 2. YamlProfileLoaderAdapter (Implements ProfileLoaderPort)

**Technology**: PyYAML  
**Features**:
- Load agent profiles from YAML files
- Support for role inheritance
- Profile validation on load
- Immutable profile entities

**Profiles Supported**:
- `architect.yaml` - System design, architecture decisions
- `developer.yaml` - Code implementation, debugging
- `qa.yaml` - Testing, test plan creation
- `devops.yaml` - Deployment, infrastructure
- `data.yaml` - Data analysis, SQL queries

#### 3. ToolExecutionAdapter (Implements ToolExecutionPort)

**Purpose**: Coordinate tool selection and execution  
**Workflow**:
1. Parse tool request from LLM output
2. Validate tool availability for agent role (RBAC)
3. Create tool instance via ToolFactory
4. Execute tool with provided parameters
5. Capture output and errors

**RBAC Integration**: Each role has allowed tools
```python
# From roles.yaml
Developer:
  allowed_tools: [file, git, test, http]
QA:
  allowed_tools: [test, http, docker, file]
```

#### 4. ToolFactory (Implements ToolFactory Pattern)

**Purpose**: Create tool instances with dependencies  
**Tools Created**:
- `FileTool` - read, write, list files
- `GitTool` - version control operations
- `DockerTool` - container operations
- `KubectlTool` - Kubernetes operations
- `HelmTool` - Helm chart operations
- `HttpTool` - HTTP requests
- `DatabaseTool` - SQL operations
- `TestTool` - test execution
- `PsqlTool` - PostgreSQL specific ops

### Factories

**VLLMAgentFactory**
- Creates fully configured VLLMAgent instances
- Injects all dependencies (adapters, tools, profile)
- Pre-validates agent configuration
- Returns ready-to-execute agent

### Mappers

| Mapper | Purpose |
|--------|---------|
| `AgentProfileMapper` | DTO â†” AgentProfile |
| `ExecutionStepMapper` | ExecutionStep â†” DTO |
| `ArtifactMapper` | Artifact â†” DTO |
| `RBACMapper` | Role YAML â†” Role entity |

### Technical Services

| Service | Purpose |
|---------|---------|
| `PromptLoader` | Load prompt templates from YAML |
| `JSONResponseParser` | Parse LLM JSON responses safely |

---

## Agent Execution Flow

### VLLMAgent ReAct Loop

```mermaid
graph TD
    A["Start Task"] --> B["Load Profile<br/>(Role, Tools, RBAC)"]
    B --> C["Generate Plan<br/>(LLM)"]
    C --> D["Initialize Loop<br/>Max iterations = N"]
    
    D --> E["Generate Next Action<br/>(LLM + Observations)"]
    E --> F{Action Type?}
    
    F -->|Tool Call| G["Validate RBAC<br/>(Role allows tool?)"]
    G -->|Allowed| H["Execute Tool"]
    G -->|Denied| I["Error: RBAC Violation"]
    
    H --> J["Capture Output<br/>+ Observation"]
    I --> J
    
    J --> K{Terminal?<br/>Success/Error/MaxIter?}
    K -->|No| L["Log Step<br/>+ Decision"]
    L --> E
    
    K -->|Yes| M["Collect Artifacts"]
    M --> N["Summarize Result"]
    N --> O["Return Execution<br/>Result + Logs"]
    
    style A fill:#e3f2fd
    style O fill:#c8e6c9
    style I fill:#ffcdd2
    style G fill:#fff9c4
```

### Sequence Example: Generate Code

```
1. Orchestrator â†’ agents_and_tools
   Task: "Create new REST endpoint for user management"

2. agents_and_tools â†’ VLLM (LoadProfile)
   Load Developer role profile
   Capabilities: [file, git, test, http]

3. agents_and_tools â†’ VLLM (GeneratePlan)
   Plan Output:
   - Step 1: Read existing endpoints structure
   - Step 2: Generate new endpoint code
   - Step 3: Add unit tests
   - Step 4: Commit to git

4. agents_and_tools â†’ Tools (ExecuteStep)
   Step 1: FileTool.read("services/api/handlers.py")
   Output: 2KB of code

5. agents_and_tools â†’ VLLM (GenerateNextAction)
   Observation: Read file contents
   Decision: Next = Generate endpoint code

6. agents_and_tools â†’ Tools (GenerateCode)
   Step 2: Use LLM to generate code
   Output: New endpoint function

7. agents_and_tools â†’ Tools (CreateTest)
   Step 3: Generate test using TestTool
   Output: Test suite

8. agents_and_tools â†’ Tools (GitCommit)
   Step 4: Commit changes using GitTool
   Output: Commit hash

9. agents_and_tools â†’ Orchestrator
   Result: {
     status: "SUCCESS",
     artifacts: [endpoint.py, test_endpoint.py],
     decisions: [...],
     execution_time: "45s"
   }
```

---

## Tools Ecosystem

### Tool Categories

#### 1. File Operations
- **FileTool**: read, write, list, delete files
- **Capabilities**: Parse any file type, handle encoding

#### 2. Version Control
- **GitTool**: commit, push, branch, merge
- **Capabilities**: Create PRs, merge with conflict resolution

#### 3. Container Operations
- **DockerTool**: build, run, stop, remove containers
- **Capabilities**: Multi-stage builds, health checks

#### 4. Orchestration
- **KubectlTool**: deploy, scale, monitor workloads
- **HelmTool**: Install/upgrade charts, manage releases

#### 5. Database Operations
- **DatabaseTool**: Execute SQL queries
- **PsqlTool**: PostgreSQL-specific operations (migrations, backups)

#### 6. Testing
- **TestTool**: Run unit/integration tests
- **Capabilities**: Parse results, coverage analysis

#### 7. HTTP
- **HttpTool**: Make HTTP requests, test APIs
- **Capabilities**: Headers, auth, response parsing

#### 8. Audit
- **AuditTool**: Record all operations for compliance
- **Capabilities**: Immutable log, signature verification

### Tool Execution Flow

```mermaid
graph LR
    A["LLM Output<br/>(Tool Request)"] --> B["Parse JSON<br/>(JSONResponseParser)"]
    B --> C["Validate<br/>RBAC"]
    C -->|Allowed| D["ToolFactory.create()"]
    C -->|Denied| E["Return Error"]
    D --> F["Execute Tool<br/>with params"]
    F --> G["Capture Output<br/>+ Errors"]
    G --> H["Return Result<br/>to Agent"]
    E --> H

    style A fill:#e3f2fd
    style H fill:#c8e6c9
    style E fill:#ffcdd2
    style C fill:#fff9c4
```

---

## Use Cases

### Use Case: Execute Code Implementation Task

**Trigger**: Orchestrator sends task to agents_and_tools  
**Input**:
```python
ExecuteTaskRequest(
    task_id="task-001",
    task_description="Implement user authentication endpoint",
    role="Developer",
    workspace="/workspace/repo",
    max_iterations=10
)
```

**Process**:
1. `LoadProfileUseCase` â†’ Load Developer profile (git, file, test, http tools)
2. `GeneratePlanUseCase` â†’ LLM creates 5-step plan
3. Loop (max 10 iterations):
   - `GenerateNextActionUseCase` â†’ Determine next action
   - `ExecuteTaskUseCase` â†’ Execute tool call
   - Validate RBAC permissions
   - Capture output
4. `CollectArtifactsUseCase` â†’ Gather all outputs
5. `SummarizeResultUseCase` â†’ Create human summary
6. `LogReasoningUseCase` â†’ Record all decisions
7. Return complete result

**Output**:
```python
TaskExecutionResult(
    task_id="task-001",
    status="SUCCESS",
    artifacts=[
        Artifact(type="code", path="auth_endpoint.py"),
        Artifact(type="test", path="test_auth.py"),
        Artifact(type="git", path="commit-abc123")
    ],
    execution_time=45.2,
    decisions=[...],  # Full audit trail
    summary="Created authentication endpoint with unit tests..."
)
```

---

## Ports & Adapters

### Port-Adapter Mapping

```mermaid
graph LR
    subgraph Ports["ðŸ”· PORTS (Interfaces)"]
        P1["LLMClientPort"]
        P2["ProfileLoaderPort"]
        P3["ToolExecutionPort"]
        P4["EventBusPort"]
    end

    subgraph Adapters["ðŸŸ¢ ADAPTERS (Implementations)"]
        A1["VLLMClientAdapter"]
        A2["YamlProfileLoaderAdapter"]
        A3["ToolExecutionAdapter"]
        A4["RedisEventBusAdapter"]
    end

    P1 -.implements.-> A1
    P2 -.implements.-> A2
    P3 -.implements.-> A3
    P4 -.implements.-> A4

    style Ports fill:#e3f2fd
    style Adapters fill:#c8e6c9
```

### Dependency Injection Example

```python
# Infrastructure layer creates all adapters
llm_adapter = VLLMClientAdapter(
    base_url="http://vllm:8000",
    model="qwen2.5-7b"
)

profile_loader = YamlProfileLoaderAdapter(
    profile_dir="/app/resources/profiles"
)

tool_execution = ToolExecutionAdapter(
    tool_factory=ToolFactory(),
    role_validator=RoleFactory()
)

# Application layer receives ports
execute_task_uc = ExecuteTaskUseCase(
    llm_client=llm_adapter,  # Port injection
    profile_loader=profile_loader,
    tool_executor=tool_execution
)

# Use case is now fully testable (mocks for all ports)
```

---

## Integration Examples

### Example 1: Create Task Execution

```python
from core.agents_and_tools.application.usecases import ExecuteTaskUseCase
from core.agents_and_tools.infrastructure.adapters import (
    VLLMClientAdapter,
    YamlProfileLoaderAdapter,
    ToolExecutionAdapter,
)
from core.agents_and_tools.infrastructure.factories import VLLMAgentFactory

# 1. Create adapters (infrastructure layer)
llm_adapter = VLLMClientAdapter(base_url="http://localhost:8000")
profile_loader = YamlProfileLoaderAdapter(profile_dir="./resources/profiles")
tool_executor = ToolExecutionAdapter(tool_factory=ToolFactory())

# 2. Create use case (application layer)
execute_task_uc = ExecuteTaskUseCase(
    llm_client=llm_adapter,
    profile_loader=profile_loader,
    tool_executor=tool_executor
)

# 3. Execute
result = await execute_task_uc.execute(
    task_description="Implement user login endpoint",
    role="Developer",
    workspace="/workspace/repo"
)

print(f"Status: {result.status}")
print(f"Artifacts: {result.artifacts}")
print(f"Summary: {result.summary}")
```

### Example 2: Load Agent Profile

```python
from core.agents_and_tools.application.usecases import LoadProfileUseCase

load_profile_uc = LoadProfileUseCase(
    profile_loader=profile_loader  # Injected
)

# Load Developer profile
profile = await load_profile_uc.execute(role="Developer")

print(f"Tools: {profile.allowed_tools}")
print(f"Max iterations: {profile.max_iterations}")
print(f"Temperature: {profile.llm_temperature}")
```

### Example 3: Direct Agent Usage

```python
from core.agents_and_tools.agents import VLLMAgent
from core.agents_and_tools.infrastructure.factories import VLLMAgentFactory

# Factory creates fully configured agent
agent_factory = VLLMAgentFactory(
    llm_adapter=llm_adapter,
    profile_loader=profile_loader,
    tool_executor=tool_executor
)

# Create Developer agent
dev_agent = await agent_factory.create(role="Developer")

# Execute task
result = await dev_agent.execute_task(
    task="Write a Python function to validate email",
    workspace="/tmp/repo"
)
```

---

## Testing & Coverage

### Unit Test Strategy

- **Domain Tests**: Validate entities, value objects, port contracts
- **Application Tests**: Mock all ports, test use case orchestration
- **Infrastructure Tests**: Mock external services (VLLM, file system)
- **Coverage Target**: â‰¥95% lines/branches

### Example Unit Test

```python
import pytest
from unittest.mock import AsyncMock

from core.agents_and_tools.application.usecases import ExecuteTaskUseCase
from core.agents_and_tools.domain.ports import LLMClientPort, ProfileLoaderPort


@pytest.fixture
def mock_llm_client():
    mock = AsyncMock(spec=LLMClientPort)
    mock.generate_completion.return_value = '{"action": "write_file", "path": "test.py"}'
    return mock


@pytest.fixture
def mock_profile_loader():
    mock = AsyncMock(spec=ProfileLoaderPort)
    mock.load_profile.return_value = AgentProfile(
        role="Developer",
        allowed_tools=["file", "git", "test"],
        max_iterations=10
    )
    return mock


@pytest.mark.asyncio
async def test_execute_task_happy_path(mock_llm_client, mock_profile_loader):
    use_case = ExecuteTaskUseCase(
        llm_client=mock_llm_client,
        profile_loader=mock_profile_loader,
        tool_executor=AsyncMock()
    )

    result = await use_case.execute(
        task_description="Write Hello World",
        role="Developer"
    )

    assert result.status == "SUCCESS"
    mock_profile_loader.load_profile.assert_awaited_once_with("Developer")


@pytest.mark.asyncio
async def test_execute_task_rejects_invalid_role(mock_profile_loader):
    mock_profile_loader.load_profile.side_effect = ValueError("Invalid role")
    
    use_case = ExecuteTaskUseCase(
        llm_client=AsyncMock(),
        profile_loader=mock_profile_loader,
        tool_executor=AsyncMock()
    )

    with pytest.raises(ValueError):
        await use_case.execute(
            task_description="Write code",
            role="InvalidRole"
        )
```

### Coverage Report

| Component | Coverage | Status |
|-----------|----------|--------|
| Agents (Domain) | 96% | âœ… |
| Tools (Domain) | 94% | âœ… |
| Use Cases | 95% | âœ… |
| Adapters | 92% | âœ… |
| Factories | 90% | âœ… |
| **Overall** | **93%** | **âœ…** |

### How to Run Tests

```bash
# All tests
pytest core/agents_and_tools/tests/

# With coverage
pytest --cov=core/agents_and_tools core/agents_and_tools/tests/

# Specific test file
pytest core/agents_and_tools/tests/unit/application/usecases/test_execute_task.py

# Specific test case
pytest core/agents_and_tools/tests/unit/application/usecases/test_execute_task.py::test_execute_task_happy_path
```

---

## Key Design Decisions

### 1. Universal Agent (VLLMAgent)

**Decision**: One agent class with role-specific profiles, not separate agent classes

**Rationale**:
- âœ… Single execution engine reduces maintenance
- âœ… Profiles define role behavior (no class explosion)
- âœ… Easy to add new roles (just add YAML profile)
- âœ… Enables agent "multi-tasking" with profile switching

### 2. Tool Factory Pattern

**Decision**: ToolFactory creates tools at execution time (lazy initialization)

**Rationale**:
- âœ… Only loaded tools that are actually used
- âœ… RBAC can deny tools without loading
- âœ… Easier to test (mock factory)
- âœ… Reduced memory footprint

### 3. ReAct Loop

**Decision**: Implement ReAct-style reasoning (Reason â†’ Act â†’ Observe loop)

**Rationale**:
- âœ… Enables complex multi-step tasks
- âœ… Full audit trail of reasoning
- âœ… Can handle errors and retry
- âœ… Supports tool chaining

### 4. YAML Profiles

**Decision**: Store agent configuration in YAML, not code

**Rationale**:
- âœ… Non-technical users can modify behaviors
- âœ… Easier to version control config changes
- âœ… Enables A/B testing different profiles
- âœ… Decouples config from deployment

### 5. Port-Based Dependencies

**Decision**: All external dependencies are ports (abstract interfaces)

**Rationale**:
- âœ… Use cases don't know about implementation details
- âœ… Easy to swap implementations (VLLM â†’ OpenAI)
- âœ… Testability (mock all ports)
- âœ… Respects Hexagonal Architecture

---

## Troubleshooting

### Issue: Agent Timeout

**Symptom**: `TimeoutError: Agent did not complete within X seconds`

**Causes**:
1. LLM server unresponsive
2. Tool execution hanging (e.g., subprocess)
3. Max iterations too high

**Solution**:
```python
# Reduce timeout or max_iterations
profile.llm_timeout = 30  # seconds
profile.max_iterations = 5
```

### Issue: RBAC Violation

**Symptom**: `PermissionError: Role 'Developer' cannot access tool 'docker'`

**Cause**: Tool not in role's allowed_tools

**Solution**: Update role profile
```yaml
# resources/profiles/developer.yaml
Developer:
  allowed_tools:
    - file
    - git
    - test
    - http
    - docker  # Add if needed
```

### Issue: LLM Response Parsing Error

**Symptom**: `JSONDecodeError: Invalid JSON response from LLM`

**Cause**: LLM returned malformed JSON

**Solution**:
1. Check LLM model and temperature (too high = more creative, less reliable)
2. Improve prompt clarity
3. Add response validation

---

## Mermaid Diagrams - Style Reference

All diagrams in this document use:
- **Grayscale + Outline**: `stroke:#333,color:#000,stroke-width:2px`
- **No background fills**: Clean, professional appearance
- **High contrast**: Readable in all viewing modes

---

## Related Documentation

- ðŸ“– [KNOWLEDGE_GRAPH_ARCHITECTURE.md](KNOWLEDGE_GRAPH_ARCHITECTURE.md) - Context precision system
- ðŸ“– [MICROSERVICES_ARCHITECTURE.md](MICROSERVICES_ARCHITECTURE.md) - Service interactions
- ðŸ“– [core/agents_and_tools/tools/README.md](../../core/agents_and_tools/tools/README.md) - Tool documentation
- ðŸ“– [core/agents_and_tools/agents/infrastructure/adapters/README.md](../../core/agents_and_tools/agents/infrastructure/adapters/README.md) - Adapter details

---

## Contributing

### Adding a New Tool

1. Create tool class in `tools/`
2. Implement required interface
3. Add to ToolFactory
4. Update profile permissions if needed
5. Add tests (mock external deps)

### Adding a New Role

1. Create YAML profile in `resources/profiles/`
2. Define allowed_tools, LLM config
3. Add role to RoleFactory
4. Test agent execution with new role

### Adding a New Use Case

1. Create use case class in `agents/application/usecases/`
2. Depend on ports (not implementations)
3. Add DTOs if needed
4. Write comprehensive unit tests
5. Document interactions

---

**Last Updated**: 2025-11-16  
**Version**: 3.0 (Consolidated from 5 documents)  
**Maintainer**: SWE AI Fleet Team

