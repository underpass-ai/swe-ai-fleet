# SWE AI Fleet

> **Open-source reference architecture for multi-agent AI software development.**  
> **Self-hostable. No cloud AI dependencies. Your data stays yours.**

[![License](https://img.shields.io/badge/License-Apache%202.0-blue.svg)](LICENSE)
[![Kubernetes](https://img.shields.io/badge/Kubernetes-1.28+-326CE5?logo=kubernetes)](https://kubernetes.io/)
[![Ray](https://img.shields.io/badge/Ray-2.49-blue?logo=ray)](https://ray.io/)
[![Coverage](https://img.shields.io/badge/Coverage-92%25-brightgreen)](https://sonarcloud.io/)

---

## ğŸ¯ What We Are

**SWE AI Fleet** is an **open-source project** building the **industry reference architecture** for **multi-agent collaborative software development**.

We're creating the **first production-ready platform** where:
- **ğŸ  100% Self-Hostable** - Deploy on your infrastructure (no cloud AI APIs)
- **ğŸ”“ Open Source LLMs** - Small models (7B-13B) that work on consumer GPUs
- **ğŸ¯ Precision Context** - Surgical context assembly makes small models perform
- **ğŸ“ˆ Horizontally Scalable** - Add GPUs = Add capacity (proven on RTX 3090)
- **ğŸ”’ Data Sovereignty** - Code never leaves your network
- **ğŸ“Š Full Transparency** - Complete audit trail, open source code

### ğŸ’° Why We're Raising Funding

We're seeking investment to become the **industry standard** for AI-powered software development, similar to how:
- **Kubernetes** became the standard for container orchestration
- **PostgreSQL** became the standard for relational databases
- **React** became the standard for UI development

**Our Goal**: Make SWE AI Fleet the **reference implementation** that enterprises, agencies, and open-source projects adopt when they need **trustable, auditable, self-hostable AI development**.

ğŸ“š **Investment Case**: [docs/investors/](docs/investors/) - Full business plan and market analysis

---

## ğŸ’¡ Why We're Different (The Real Innovation)

### The Problem: Dependency on Cloud AI Giants

```
âŒ GitHub Copilot: Depends on OpenAI â†’ Vendor lock-in
âŒ Cursor/Windsurf: Depends on Claude â†’ Data privacy concerns
âŒ Devin/etc: Cloud-only â†’ No self-hosting option
âŒ All use massive context â†’ Requires huge models (GPT-4, Claude 3.5)
```

**Consequences**:
- ğŸ”’ **Vendor Lock-In**: Can't switch providers easily
- ğŸ’° **Unpredictable Costs**: Token pricing changes at provider's will
- ğŸš« **Data Privacy**: Your code goes to third parties
- âš–ï¸ **Compliance Issues**: GDPR, SOC2, industry regulations
- ğŸ“ˆ **Non-Scalable**: Costs grow linearly with usage

### Our Revolutionary Solution: Precision Context + Small LLMs

```
âœ… SWE AI Fleet: Self-hostable â†’ Your infrastructure, your control
âœ… Small LLMs (7B-13B) â†’ Run on consumer GPUs (RTX 3090, 4090)
âœ… Precision Context â†’ Small models perform like large ones
âœ… Horizontally Scalable â†’ More GPUs = More capacity
âœ… 100% Private â†’ Code never leaves your network
```

**The Breakthrough**: 

**IF** you provide **surgically-precise context** (only the 30 relevant lines)  
**THEN** a **small 7B model** performs as well as GPT-4 with massive context  
**RESULT**: Self-hostable, private, scalable AI development

### How Precision Context Works

```
Traditional Approach (Massive Context):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dump entire codebase into prompt   â”‚
â”‚  â€¢ 50,000 lines of code             â”‚
â”‚  â€¢ 200+ pages of docs               â”‚
â”‚  â€¢ 1,000+ commits                   â”‚
â”‚  â€¢ Result: 100K+ tokens             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Requires GPT-4 / Claude 3.5
   (175B+ parameters, cloud-only)


Our Approach (Precision Context):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Knowledge Graph extracts ONLY:     â”‚
â”‚  â€¢ 30 lines relevant code           â”‚
â”‚  â€¢ 3 test failures                  â”‚
â”‚  â€¢ 2 related decisions              â”‚
â”‚  â€¢ 5 lines API spec                 â”‚
â”‚  â€¢ Result: 200 tokens               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Works with Qwen/Llama 7B-13B
   (Self-hostable, runs on RTX 3090)
```

**Key Insight**: **Perfect task definition** + **Precise context** = **Small model succeeds**

### Why This Matters

| Challenge | Cloud AI Solutions | SWE AI Fleet | Impact |
|-----------|-------------------|--------------|--------|
| **Data Privacy** | Code sent to third parties | **100% on-premise** | GDPR/SOC2 compliant âœ… |
| **Vendor Lock-in** | Locked to OpenAI/Anthropic | **No dependencies** | Freedom to evolve âœ… |
| **Scalability** | Pay per token (unpredictable) | **Add GPUs** (predictable) | Fixed infrastructure costs âœ… |
| **Model Size** | 175B+ params (cloud-only) | **7B-13B** (RTX 3090/4090) | Runs on consumer hardware âœ… |
| **Context Strategy** | Massive context (100K+ tokens) | **Precision** (200 tokens) | Small models work âœ… |
| **Compliance** | Data leaves your network | **Never leaves** | Regulatory compliant âœ… |

ğŸ’ **Core Value Propositions**: 

**For Enterprises**:
- âœ… Data sovereignty (code never leaves your infrastructure)
- âœ… Regulatory compliance (GDPR, SOC2, HIPAA-ready)
- âœ… No vendor lock-in (open source, self-hosted)
- âœ… Predictable costs (fixed infrastructure, not per-token)

**For Development Teams**:
- âœ… Multi-agent deliberation (team intelligence, not single AI)
- âœ… Role-specialized agents (DEV, QA, ARCHITECT, etc.)
- âœ… Precision context (AI gets ONLY what matters for the task)
- âœ… Horizontally scalable (more GPUs = more capacity)

**For Compliance & Security**:
- âœ… 100% on-premise deployment
- âœ… Full audit trail (every decision logged)
- âœ… No external API calls
- âœ… Open source (auditable code)

ğŸ“š **Technical Deep-Dive**: [docs/investors/CONTEXT_PRECISION_TECHNOLOGY.md](docs/investors/CONTEXT_PRECISION_TECHNOLOGY.md)

---

## ğŸ† What Makes Us Unique

### 1. **Precision Context Technology** (Our Secret Sauce)
- **Knowledge Graph**: Neo4j-powered context assembly
- **Role-Specific Packs**: Each agent gets ONLY what they need
- **Context Scoring**: AI-scored relevance (avoid noise)
- **30 lines vs 50,000 lines**: 99.9% reduction in tokens

### 2. **Multi-Agent Deliberation** (Team Intelligence)
- **5 Specialized Roles**: DEV, QA, ARCHITECT, DEVOPS, DATA
- **Peer Review**: Agents critique each other's proposals
- **Consensus Building**: Best solution wins through scoring
- **3-agent councils**: Diversity + Speed balance

### 3. **Production-Ready Architecture** (Enterprise-Grade)
- **Hexagonal Architecture**: Clean, testable, maintainable
- **Event-Driven**: NATS JetStream for async workflows
- **GPU-Accelerated**: Ray + vLLM for performance
- **92% Test Coverage**: Production-ready quality

### 4. **Full Observability** (Trust Through Transparency)
- **Every LLM call logged**: See what agents "think"
- **Decision graph**: Knowledge graph tracks all decisions
- **FSM workflows**: Clear state transitions
- **Audit trail**: Complete history of every change

---

## ğŸ¯ Who We Serve

### Target Users
- **Enterprise Development Teams** (50-500 developers)
- **Software Agencies** (high-volume, quality-critical)
- **Startups** (fast iteration, limited resources)
- **Open Source Projects** (community-driven development)

### Use Cases
- âœ… Feature development (stories â†’ code â†’ tests â†’ deploy)
- âœ… Bug fixing (context-aware, role-specific)
- âœ… Refactoring (architectural changes)
- âœ… Code review (multi-agent consensus)
- âœ… Documentation (auto-generated, accurate)

---

## âœ¨ Key Features

- **ğŸ¤– Multi-Agent Deliberation**: Agents collaborate with peer review and consensus
- **ğŸ¯ Precision Context**: Knowledge graph-powered surgical context assembly (our differentiator)
- **ğŸ“Š FSM-Driven Workflows**: Statechart-based user story lifecycle management
- **âš¡ GPU-Accelerated**: Distributed execution with Ray and time-sliced GPUs
- **ğŸ—ï¸ Hexagonal Architecture**: Clean architecture with ports & adapters
- **ğŸ” Full Observability**: Complete LLM "thinking" process visible

## ğŸš€ Quick Start

### Prerequisites

- Kubernetes cluster (1.28+)
- kubectl configured
- cert-manager & ingress-nginx installed

See [full prerequisites](docs/getting-started/prerequisites.md) for details.

### Deploy

```bash
# 1. Clone repository
git clone https://github.com/yourusername/swe-ai-fleet
cd swe-ai-fleet

# 2. Verify prerequisites
./scripts/infra/00-verify-prerequisites.sh

# 3. Deploy everything
./scripts/infra/deploy-all.sh

# 4. Verify health
./scripts/infra/verify-health.sh
```

### Access

```bash
# Expose UI publicly (optional)
./scripts/infra/06-expose-ui.sh

# Access at https://swe-fleet.underpassai.com
```

ğŸ“š **Full Guide**: [Getting Started](docs/getting-started/README.md)

## ğŸ—ï¸ Architecture

### Microservices

| Service | Language | Purpose |
|---------|----------|---------|
| **Planning** | Go | FSM-based workflow & story lifecycle |
| **StoryCoach** | Go | User story quality scoring (DoR/INVEST) |
| **Workspace** | Go | Agent work validation & rigor scoring |
| **PO UI** | React | Product Owner interface |
| **Agent Orchestrator** | Python | Multi-agent deliberation (planned) |

### Technology Stack

- **Frontend**: React + Tailwind + Vite
- **Async Messaging**: NATS JetStream
- **Sync RPC**: gRPC + Protocol Buffers
- **Agent Execution**: Ray (GPU-accelerated)
- **Context Store**: Neo4j (planned)
- **Container Runtime**: CRI-O / containerd

ğŸ“š **Details**: [Architecture Documentation](docs/architecture/README.md)

---

## ğŸ›ï¸ **IMPORTANTE: Estructura de CÃ³digo**

### ğŸ”µ CORE vs ğŸŸ¢ MICROSERVICIOS

El proyecto tiene **DOS capas de cÃ³digo completamente diferentes**:

```
swe-ai-fleet/
â”œâ”€â”€ src/swe_ai_fleet/          ğŸ”µ CORE - LÃ³gica de Negocio Reutilizable
â”‚   â”œâ”€â”€ orchestrator/          â† Algoritmos de orchestration
â”‚   â”œâ”€â”€ agents/                â† Implementaciones de agentes (VLLMAgent, etc.)
â”‚   â”œâ”€â”€ context/               â† LÃ³gica de context management
â”‚   â””â”€â”€ ray_jobs/              â† Ray job execution logic
â”‚
â””â”€â”€ services/                  ğŸŸ¢ MICROSERVICIOS - gRPC/HTTP Servers
    â”œâ”€â”€ orchestrator/          â† Orchestrator MS (Hexagonal Architecture)
    â”œâ”€â”€ context/               â† Context MS (Hexagonal Architecture)
    â”œâ”€â”€ ray-executor/          â† Ray Executor MS
    â””â”€â”€ monitoring/            â† Monitoring Dashboard (FastAPI)
```

### ğŸ“– **DocumentaciÃ³n CrÃ­tica (LÃ‰ELO PRIMERO)**:

| Documento | PropÃ³sito | CuÃ¡ndo Leer |
|-----------|-----------|-------------|
| **[ARCHITECTURE_CORE_VS_MICROSERVICES.md](ARCHITECTURE_CORE_VS_MICROSERVICES.md)** | **Explica diferencia CORE vs MS** | â­ ANTES de tocar cÃ³digo |
| **[ORCHESTRATOR_HEXAGONAL_CODE_ANALYSIS.md](ORCHESTRATOR_HEXAGONAL_CODE_ANALYSIS.md)** | AnÃ¡lisis completo del Orchestrator hexagonal | Al trabajar con Orchestrator |
| **[DELIBERATION_USECASES_ANALYSIS.md](DELIBERATION_USECASES_ANALYSIS.md)** | Por quÃ© hay 3 clases "Deliberate" | Cuando veas duplicados |
| **[REFACTOR_DIRECTORY_STRUCTURE_PROPOSAL.md](REFACTOR_DIRECTORY_STRUCTURE_PROPOSAL.md)** | Propuesta renombrar `src/` â†’ `core/` | Futura iteraciÃ³n |

### âš ï¸ **Confusiones Comunes**:

1. **"Â¿Por quÃ© hay cÃ³digo en `src/` Y en `services/`?"**  
   â†’ `src/` = CORE reutilizable, `services/` = Microservicios que USAN el core

2. **"Â¿Por quÃ© hay 2-3 clases con nombres similares?"**  
   â†’ Una es CORE (algoritmo), otra es WRAPPER hexagonal (stats/events)

3. **"Â¿DÃ³nde hago cambios de lÃ³gica de negocio?"**  
   â†’ En `src/` (CORE), los microservicios lo importan

4. **"Â¿DÃ³nde hago cambios de APIs/gRPC/NATS?"**  
   â†’ En `services/` (MICROSERVICIOS)

**ğŸ“š Lee [ARCHITECTURE_CORE_VS_MICROSERVICES.md](ARCHITECTURE_CORE_VS_MICROSERVICES.md) para detalles completos.**

---

## ğŸ“Š System Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PO UI     â”‚ â† Product Owner manages stories
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (gRPC)
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Planning   â”‚â”€â”€â”€â”€â†’â”‚ StoryCoach   â”‚ â† Score stories
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (NATS events)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     NATS     â”‚ â† Event backbone
â”‚  JetStream   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (agent.requests)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrator â”‚â”€â”€â”€â”€â†’â”‚  RayCluster  â”‚ â† GPU workers
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ (agent.responses)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Workspace   â”‚ â† Validate agent work
â”‚   Scorer     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“š Documentation

### ğŸš€ Getting Started
- [Prerequisites](docs/getting-started/prerequisites.md)
- [Installation](docs/getting-started/README.md)

### ğŸ—ï¸ Architecture (NORMATIVE)
- **[Hexagonal Architecture](HEXAGONAL_ARCHITECTURE_PRINCIPLES.md)** - Architectural principles â­
- **[Testing Architecture](docs/TESTING_ARCHITECTURE.md)** - Testing strategy & execution â­
- [Microservices](docs/architecture/microservices.md)
- [API Specifications](specs/)
- [FSM Workflow](docs/architecture/fsm-workflow.md)

### ğŸ”§ Infrastructure
- [Kubernetes Deployment](docs/infrastructure/kubernetes.md)
- [GPU Setup & Time-Slicing](docs/infrastructure/GPU_TIME_SLICING.md)
- [Ray Cluster](docs/infrastructure/RAYCLUSTER_INTEGRATION.md)

### ğŸ› ï¸ Development
- [Contributing Guide](docs/development/CONTRIBUTING.md)
- [Development Setup](docs/development/DEVELOPMENT_GUIDE.md)
- [Git Workflow](docs/development/GIT_WORKFLOW.md)

### ğŸš€ Operations
- [Troubleshooting](docs/operations/K8S_TROUBLESHOOTING.md)
- [Monitoring](docs/operations/monitoring.md)

### ğŸ“– Reference
- [Glossary](docs/reference/GLOSSARY.md)
- [FAQ](docs/reference/FAQ.md)
- [RFCs](docs/reference/rfcs/)

## ğŸŒŸ Features

### âœ… Implemented

- [x] Microservices architecture (Planning, StoryCoach, Workspace, UI)
- [x] NATS JetStream messaging
- [x] FSM-based workflow engine
- [x] User story quality scoring (DoR/INVEST/Gherkin)
- [x] Agent work validation with adjustable rigor
- [x] React UI with Tailwind
- [x] Kubernetes deployment
- [x] GPU time-slicing support
- [x] Local container registry
- [x] TLS with cert-manager

### ğŸš§ In Progress

- [ ] Agent Orchestrator service
- [ ] Multi-agent deliberation
- [ ] Context Service (Neo4j)
- [ ] Workspace Runner (Python)
- [ ] LLM integrations

### ğŸ”® Planned

- [ ] Gateway service (REST API)
- [ ] OpenTelemetry observability
- [ ] Multi-tenant support
- [ ] Agent marketplace

See [Roadmap](docs/vision/ROADMAP.md) for details.

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](docs/development/CONTRIBUTING.md).

### Development Setup

```bash
# Install dependencies
make install-deps

# Run tests (see docs/TESTING_ARCHITECTURE.md)
make test-unit         # Unit tests (~3s)
make test-integration  # Integration tests (~45s)
make test-e2e         # E2E tests (~3-5min)
make test-all         # All tests

# Build services
cd services && make build

# Run locally
./scripts/dev/dev.sh
```

ğŸ“š **Testing Guide**: [docs/TESTING_ARCHITECTURE.md](docs/TESTING_ARCHITECTURE.md) - Documento normativo Ãºnico

## ğŸ“„ License

This project is licensed under the Apache License 2.0. See [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

Built with:
- [NATS](https://nats.io/) - Cloud-native messaging
- [Ray](https://ray.io/) - Distributed compute
- [gRPC](https://grpc.io/) - RPC framework
- [React](https://react.dev/) - UI framework
- [Kubernetes](https://kubernetes.io/) - Container orchestration

## ğŸ“§ Contact

- **Issues**: [GitHub Issues](https://github.com/underpass-ai/swe-ai-fleet/issues)
- **Email**: contact@underpassai.com

---

â­ **Star us on GitHub** if you find this project useful!