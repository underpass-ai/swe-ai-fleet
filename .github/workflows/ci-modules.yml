name: CI - Modular Build and Test

permissions:
  contents: read
  pull-requests: write

on:
  pull_request:
  push:
    branches:
      - '**'

jobs:
  # Build and test each module independently
  test-module:
    name: Test ${{ matrix.module }}
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix:
        include:
          # Core modules (tested individually)
          - module: core/shared
            artifact-name: core-shared
            python-version: '3.13'
          - module: core/memory
            artifact-name: core-memory
            python-version: '3.13'
          - module: core/context
            artifact-name: core-context
            python-version: '3.13'
          - module: core/orchestrator
            artifact-name: core-orchestrator
            python-version: '3.13'
          - module: core/agents_and_tools
            artifact-name: core-agents_and_tools
            python-version: '3.13'
          - module: core/ray_jobs
            artifact-name: core-ray_jobs
            python-version: '3.11'
          - module: core/reports
            artifact-name: core-reports
            python-version: '3.13'
          # Service modules
          - module: services/backlog_review_processor
            artifact-name: services-backlog_review_processor
            python-version: '3.13'
          - module: services/context
            artifact-name: services-context
            python-version: '3.13'
          - module: services/orchestrator
            artifact-name: services-orchestrator
            python-version: '3.13'
          - module: services/planning
            artifact-name: services-planning
            python-version: '3.13'
          - module: services/ray_executor
            artifact-name: services-ray_executor
            python-version: '3.11'
          - module: services/task_derivation
            artifact-name: services-task_derivation
            python-version: '3.13'
          - module: services/workflow
            artifact-name: services-workflow
            python-version: '3.13'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          pip install --upgrade pip
          # Select constraints based on Python version.
          if [ "${{ matrix.python-version }}" = "3.11" ]; then
            CONSTRAINTS="constraints-py311.txt"
          else
            CONSTRAINTS="constraints.txt"
          fi

          # Install root project dev dependencies (best-effort; root requires Python >= 3.13).
          pip install -c "$CONSTRAINTS" -e ".[dev]" || echo "â„¹ï¸  Root package not installable for this Python, continuing..."

          # Install only the compatible modules for the interpreter (script is Python-aware).
          ./scripts/install-modules.sh

      - name: Generate protobuf files (if needed)
        if: contains(matrix.module, 'services/') || contains(matrix.module, 'core/context') || contains(matrix.module, 'core/orchestrator')
        run: |
          if [ -f "${{ matrix.module }}/generate-protos.sh" ]; then
            if [ "${{ matrix.python-version }}" = "3.11" ]; then
              CONSTRAINTS="constraints-py311.txt"
            else
              CONSTRAINTS="constraints.txt"
            fi
            pip install -c "$CONSTRAINTS" grpcio-tools
            bash "${{ matrix.module }}/generate-protos.sh"
          fi

          # Some modules depend on gRPC clients from other services.
          # Use the shared helper to generate those protos as well, mirroring local `make generate-protos-module`.
          if [ "${{ matrix.module }}" = "services/ray_executor" ]; then
            # Ray Executor tests use the orchestrator gRPC client via RayExecutorMapper
            ./scripts/generate-protos-module.sh services/orchestrator
          fi

      - name: Run tests for module
        run: |
          ./scripts/test-module.sh ${{ matrix.module }} --cov-report=xml --cov-report=json

      - name: Upload coverage
        run: |
          # Ensure .coverage file exists (pytest-cov generates it automatically)
          if [ -f "${{ matrix.module }}/.coverage" ]; then
            echo "âœ… Found .coverage file"
          else
            echo "âš ï¸  .coverage file not found in ${{ matrix.module }}/"
            # List files in module directory for debugging
            ls -la "${{ matrix.module }}/" | grep -E "(coverage|\.coverage)" || echo "No coverage files found"
          fi
        continue-on-error: true

      - name: Upload coverage artifacts
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.artifact-name }}-${{ matrix.python-version }}
          path: |
            ${{ matrix.module }}/.coverage
            ${{ matrix.module }}/coverage.xml
            ${{ matrix.module }}/coverage.json
          retention-days: 1
          if-no-files-found: warn

  # Combine coverage reports
  combine-coverage:
    name: Combine Coverage Reports
    runs-on: ubuntu-latest
    needs: test-module
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.13'

      - name: Download all coverage artifacts
        uses: actions/download-artifact@v4
        with:
          path: coverage-reports

      - name: Combine coverage reports
        run: |
          pip install coverage
          # Use root pyproject.toml for coverage configuration (normalizes paths)
          export COVERAGE_FILE=.coverage
          
          # Combine all .coverage data files (not XML reports)
          # Find all .coverage files recursively (artifacts preserve directory structure)
          COVERAGE_FILES=$(find coverage-reports -name ".coverage" -type f 2>/dev/null || true)
          if [ -n "$COVERAGE_FILES" ]; then
            echo "ðŸ“Š Found coverage data files:"
            echo "$COVERAGE_FILES"
            # Combine all .coverage files
            # Note: coverage combine uses the root pyproject.toml [tool.coverage.paths] to normalize paths
            echo "$COVERAGE_FILES" | while IFS= read -r cov_file; do
              if [ -f "$cov_file" ]; then
                echo "  Combining: $cov_file"
                coverage combine "$cov_file" || echo "  âš ï¸  Failed to combine $cov_file (continuing...)"
              fi
            done
            
            # Show combined coverage summary for debugging
            echo ""
            echo "ðŸ“Š Combined coverage summary:"
            coverage report --skip-covered --skip-empty || echo "  (No coverage data to report)"
            echo ""
            
            # Generate final coverage.xml from combined data
            # This will use the root pyproject.toml configuration which normalizes paths
            if coverage xml -o coverage.xml 2>&1; then
              echo "âœ… Combined coverage report generated: coverage.xml"
              # Verify the file was created and has content
              if [ -f "coverage.xml" ]; then
                FILE_SIZE=$(wc -c < coverage.xml)
                if [ "$FILE_SIZE" -gt 100 ]; then
                  echo "âœ… coverage.xml exists (${FILE_SIZE} bytes) and is ready for SonarCloud"
                  # Show a sample of what's in the coverage.xml for debugging
                  echo "ðŸ“‹ Sample of coverage.xml (first 20 lines):"
                  head -20 coverage.xml || true
                else
                  echo "âš ï¸  coverage.xml is too small (${FILE_SIZE} bytes) - may be empty"
                fi
              else
                echo "âŒ coverage.xml was not created"
                exit 1
              fi
            else
              echo "âš ï¸  Failed to generate coverage.xml from combined data"
              # Fallback: try to use first available coverage.xml
              FIRST_COV=$(find coverage-reports -name "coverage.xml" -type f 2>/dev/null | head -1)
              if [ -n "$FIRST_COV" ] && [ -f "$FIRST_COV" ]; then
                cp "$FIRST_COV" coverage.xml
                echo "âœ… Using first available coverage.xml as fallback: $FIRST_COV"
              else
                echo "âŒ No coverage data available"
                exit 1
              fi
            fi
          else
            echo "âš ï¸  No .coverage files found to combine"
            # Fallback: try to use first available coverage.xml
            FIRST_COV=$(find coverage-reports -name "coverage.xml" -type f 2>/dev/null | head -1)
            if [ -n "$FIRST_COV" ] && [ -f "$FIRST_COV" ]; then
              cp "$FIRST_COV" coverage.xml
              echo "âœ… Using first available coverage.xml as fallback: $FIRST_COV"
            else
              echo "âŒ No coverage data available"
              exit 1
            fi
          fi

      - name: Upload combined coverage
        uses: actions/upload-artifact@v4
        with:
          name: python-coverage
          path: coverage.xml
          retention-days: 1

  # UI Tests (independent)
  ui-tests:
    name: Unit Tests (UI)
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: services/planning-ui/package-lock.json

      - name: Install UI dependencies
        working-directory: services/planning-ui
        run: npm ci

      - name: Generate gRPC code from protobuf
        working-directory: services/planning-ui
        run: npm run generate-grpc

      - name: Run UI tests with coverage
        working-directory: services/planning-ui
        run: npm run test:coverage

      - name: Upload UI coverage
        uses: actions/upload-artifact@v4
        with:
          name: ui-coverage
          path: services/planning-ui/coverage/lcov.info
          retention-days: 1

  # SonarCloud Analysis
  sonarcloud-analysis:
    name: SonarCloud Analysis
    runs-on: ubuntu-latest
    needs: [combine-coverage, ui-tests]
    if: always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Download Python coverage
        uses: actions/download-artifact@v4
        with:
          name: python-coverage
          path: .

      - name: Download UI coverage
        uses: actions/download-artifact@v4
        with:
          name: ui-coverage
          path: services/planning-ui/coverage/

      - name: SonarCloud Scan (Pull Request)
        if: github.event_name == 'pull_request'
        uses: sonarsource/sonarcloud-github-action@v3.1
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_HOST_URL: https://sonarcloud.io
        with:
          projectBaseDir: ${{ github.workspace }}
          args: >
            -Dsonar.organization=underpass-ai-swe-ai-fleet
            -Dsonar.projectKey=underpass-ai-swe-ai-fleet
            -Dsonar.pullrequest.key=${{ github.event.number }}
            -Dsonar.pullrequest.branch=${{ github.head_ref }}
            -Dsonar.pullrequest.base=${{ github.base_ref }}
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.javascript.lcov.reportPaths=services/planning-ui/coverage/lcov.info
            -Dsonar.typescript.lcov.reportPaths=services/planning-ui/coverage/lcov.info
            -Dsonar.scanner.image=sonarsource/sonar-scanner-cli:11.1

      - name: SonarCloud Scan (Main Branch)
        if: >
          github.event_name == 'push' &&
          github.ref_name == 'main'
        uses: sonarsource/sonarcloud-github-action@v3.1
        env:
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_HOST_URL: https://sonarcloud.io
        with:
          projectBaseDir: ${{ github.workspace }}
          args: >
            -Dsonar.organization=underpass-ai-swe-ai-fleet
            -Dsonar.projectKey=underpass-ai-swe-ai-fleet
            -Dsonar.python.coverage.reportPaths=coverage.xml
            -Dsonar.javascript.lcov.reportPaths=services/planning-ui/coverage/lcov.info
            -Dsonar.typescript.lcov.reportPaths=services/planning-ui/coverage/lcov.info
            -Dsonar.scanner.image=sonarsource/sonar-scanner-cli:11.1

