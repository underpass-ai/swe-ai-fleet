# RayCluster for Agent Execution
# Optimizado para estación de trabajo de alto rendimiento
# 
# Hardware recomendado:
#   - CPU: AMD Threadripper PRO 5955WX (16c/32t) o superior
#   - RAM: 512GB (8x64GB DDR4 ECC, 8 canales)
#   - GPU: 4-8x RTX 3090/4090 (24GB VRAM c/u)
#   - Plataforma: WRX80 (soporte multi-GPU, 128 PCIe lanes)
#
# Este YAML está integrado con tu RayCluster existente en namespace 'ray'
# Si deseas usar un cluster separado para swe-ai-fleet, despliega este archivo.
# Si prefieres usar el existente, consulta RAYCLUSTER_INTEGRATION.md
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ray-agent-sa
  namespace: swe-ai-fleet
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: ray-agent-role
  namespace: swe-ai-fleet
rules:
  - apiGroups: [""]
    resources: ["pods", "pods/log"]
    verbs: ["get", "list", "watch"]
  - apiGroups: [""]
    resources: ["configmaps", "secrets"]
    verbs: ["get", "list"]
  - apiGroups: ["batch"]
    resources: ["jobs"]
    verbs: ["create", "get", "list", "watch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: ray-agent-rolebinding
  namespace: swe-ai-fleet
subjects:
  - kind: ServiceAccount
    name: ray-agent-sa
roleRef:
  kind: Role
  name: ray-agent-role
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: ray.io/v1
kind: RayCluster
metadata:
  name: agent-cluster
  namespace: swe-ai-fleet
  labels:
    app: ray-agents
    tier: agent-execution
spec:
  rayVersion: '2.49.2'
  enableInTreeAutoscaling: true
  
  headGroupSpec:
    serviceType: ClusterIP
    rayStartParams:
      dashboard-host: '0.0.0.0'
      num-cpus: '0'  # Head node no ejecuta tareas de agente
      num-gpus: '0'
    template:
      metadata:
        labels:
          app: ray-head
          ray-cluster: agent-cluster
      spec:
        serviceAccountName: ray-agent-sa
        nodeSelector:
          kubernetes.io/hostname: wrx80-node1
        containers:
          - name: ray-head
            image: docker.io/rayproject/ray:2.49.2
            imagePullPolicy: IfNotPresent
            ports:
              - containerPort: 6379
                name: gcs
                protocol: TCP
              - containerPort: 8265
                name: dashboard
                protocol: TCP
              - containerPort: 10001
                name: client
                protocol: TCP
              - containerPort: 8000
                name: serve
                protocol: TCP
            resources:
              requests:
                cpu: "2"
                memory: 16Gi
              limits:
                cpu: "8"
                memory: 32Gi
            env:
              - name: RAY_CLUSTER_NAME
                value: "agent-cluster"
              - name: RAY_LOG_TO_STDERR
                value: "1"
  
  workerGroupSpecs:
    # GPU Workers - Configuración optimizada para 4-8 GPUs
    # Cada worker tiene acceso a 1 GPU para ejecutar agentes con LLMs locales
    - groupName: gpu-workers
      replicas: 8
      minReplicas: 4    # Mínimo para aprovechar las 4 GPUs físicas
      maxReplicas: 8    # Máximo si tienes 8 GPUs o usas time-sharing
      numOfHosts: 1
      rayStartParams:
        num-gpus: '1'
        num-cpus: '3'   # 3 CPUs por GPU worker (24 CPUs total para 8 workers)
      template:
        metadata:
          labels:
            app: ray-worker
            ray-cluster: agent-cluster
            worker-type: gpu
        spec:
          serviceAccountName: ray-agent-sa
          nodeSelector:
            kubernetes.io/hostname: wrx80-node1
          containers:
            - name: ray-worker
              image: docker.io/rayproject/ray:2.49.2
              imagePullPolicy: IfNotPresent
              resources:
                requests:
                  cpu: "3"
                  memory: 56Gi
                  nvidia.com/gpu: 1
                limits:
                  cpu: "12"
                  memory: 64Gi
                  nvidia.com/gpu: 1
              env:
                - name: RAY_CLUSTER_NAME
                  value: "agent-cluster"
                - name: CUDA_VISIBLE_DEVICES
                  value: "0"  # Ray maneja la asignación automáticamente
---
# Ray Dashboard Service (para monitoreo interno)
apiVersion: v1
kind: Service
metadata:
  name: ray-dashboard
  namespace: swe-ai-fleet
  labels:
    app: ray-dashboard
spec:
  selector:
    app: ray-head
    ray-cluster: agent-cluster
  ports:
    - port: 8265
      targetPort: 8265
      name: dashboard
  type: ClusterIP
---
# Ray Client Service (para conexión desde workspace runner)
apiVersion: v1
kind: Service
metadata:
  name: ray-client
  namespace: swe-ai-fleet
  labels:
    app: ray-client
spec:
  selector:
    app: ray-head
    ray-cluster: agent-cluster
  ports:
    - port: 10001
      targetPort: 10001
      name: client
  type: ClusterIP