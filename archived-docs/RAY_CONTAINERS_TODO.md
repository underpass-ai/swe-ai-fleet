# TODO: Ray en Containers para E2E Tests

## ğŸ¯ Objetivo

Conseguir que Ray funcione correctamente en containers (Podman/Docker) para ejecutar tests E2E con la arquitectura Ray + vLLM completa dentro de un entorno containerizado.

---

## âŒ Problema Actual

### Lo que NO Funciona
**Ray en container NO es accesible desde el host para ejecutar jobs.**

**SÃ­ntoma**:
```python
ray.init(address="localhost:36379")
# Error: Can't find `node_ip_address.json` file
# ValueError: A ray instance hasn't started
```

**Causa raÃ­z**:
- Ray en container tiene IP interna (10.89.0.x)
- El cliente desde el host intenta conectar vÃ­a localhost:36379
- Ray busca archivos de sesiÃ³n en /tmp/ray/ del HOST
- No encuentra la sesiÃ³n del Ray que corre en el CONTAINER

---

## âœ… Lo que SÃ Funciona

### 1. Ray en Kubernetes
```
âœ… Ray cluster en K8s (namespace: ray)
âœ… Orchestrator conecta vÃ­a ray://ray-head:10001
âœ… VLLMAgentJob ejecuta correctamente
âœ… Todo funciona en producciÃ³n
```

### 2. Ray Container Standalone
```
âœ… Ray container inicia correctamente
âœ… Ray status: healthy
âœ… Logs muestran "Ray runtime started"
âœ… Dashboard accesible (si se expone)
```

### 3. vLLM en Container
```
âœ… vLLM con GPU en Podman funciona perfectamente
âœ… nvidia-smi accesible desde container
âœ… Modelo carga correctamente
âœ… API /health responde 200 OK
```

---

## ğŸ” InvestigaciÃ³n Necesaria

### OpciÃ³n A: Ray Client API
**TeorÃ­a**: Usar Ray Client API en lugar de conexiÃ³n directa

```yaml
# docker-compose.yml
ray-server:
  command: ray start --head --ray-client-server-port=10001
  ports:
    - "10001:10001"  # Ray Client port
```

```python
# Cliente
ray.init("ray://localhost:10001")  # Ray Client protocol
```

**Estado**: NO probado aÃºn  
**Dificultad**: Media  
**Docs**: https://docs.ray.io/en/latest/cluster/running-applications/job-submission/ray-client.html

### OpciÃ³n B: Todo Dentro de Containers
**TeorÃ­a**: Tests corren DENTRO de un container en el mismo network

```yaml
tests:
  container_name: orchestrator-e2e-tests
  environment:
    - RAY_ADDRESS=ray://ray-server:10001  # Nombre de servicio, no localhost
  networks:
    - orchestrator-e2e-network
  command: pytest tests/
```

**Estado**: Parcialmente implementado  
**Dificultad**: Baja  
**Problema actual**: Orchestrator container no arranca (falta debuggear por quÃ©)

### OpciÃ³n C: Ray en Host
**TeorÃ­a**: Ray corre en el host, containers se conectan a Ã©l

```bash
# En host
ray start --head --port=6379

# Container
environment:
  - RAY_ADDRESS=ray://host.containers.internal:10001
```

**Estado**: NO probado  
**Dificultad**: Media  
**Problema**: Requiere configurar network host mode

### OpciÃ³n D: Skip Ray en E2E Containers
**TeorÃ­a**: E2E containers usan MockAgents, Ray solo en Kubernetes

**Estado**: **RECOMENDADO para ahora**  
**Dificultad**: Ninguna (ya funciona)  
**JustificaciÃ³n**:
- E2E containers validan lÃ³gica de negocio (sin Ray)
- Ray + vLLM validado en Kubernetes (ambiente real)
- Menos complejidad en E2E setup

---

## ğŸ“‹ Archivos Creados (Para InvestigaciÃ³n Futura)

```
tests/e2e/services/orchestrator/
â”œâ”€â”€ docker-compose.ray-vllm.yml          # Compose con Ray + vLLM
â”œâ”€â”€ run-e2e-ray-vllm.sh                 # Script de ejecuciÃ³n
â””â”€â”€ README_RAY_VLLM.md                   # DocumentaciÃ³n

tests/integration/orchestrator/
â””â”€â”€ test_vllm_agent_integration.py       # Tests sin Ray âœ…
```

**Estado**: Preparados pero no validados end-to-end con Ray en containers

---

## ğŸ¯ Estrategia de Testing Actual (VALIDADA)

### 1. Unit Tests (516 tests) âœ…
- Sin dependencias externas
- VLLMAgentJobBase, DeliberateAsync
- Mocks para vLLM y NATS
- **100% passing**

### 2. Integration Tests (3 tests) âœ…
- VLLMAgentJobBase con vLLM real (opcional)
- Sin Ray (usa clase base)
- Requiere vLLM corriendo
- **Skipped por defecto, run manual cuando vLLM disponible**

### 3. E2E Containers (38 tests) âœ…
- Orchestrator + NATS + Redis
- MockAgents (no Ray, no vLLM)
- **100% passing en containers**

### 4. E2E Kubernetes (6 tests) âœ…
- Orchestrator + Ray + vLLM + GPUs
- Ambiente real de producciÃ³n
- **100% passing en cluster K8s**

---

## âœ… ConclusiÃ³n

**No necesitamos Ray en containers para validar el sistema.**

### Cobertura Actual (Excelente)
- âœ… LÃ³gica validada: Unit tests
- âœ… IntegraciÃ³n validada: Integration tests (sin Ray)
- âœ… Containers validados: E2E containers (MockAgents)
- âœ… ProducciÃ³n validada: E2E en Kubernetes (Ray + vLLM real)

### Ray en Containers = Nice to Have
- No es crÃ­tico para validaciÃ³n
- Sistema ya 100% probado sin esto
- Puede investigarse en el futuro si se necesita
- OpciÃ³n D (skip Ray en E2E containers) es la mÃ¡s pragmÃ¡tica

---

## ğŸ”¬ Para Investigar en el Futuro

Si en algÃºn momento queremos Ray en containers (no urgente):

1. **Probar OpciÃ³n B**: Tests dentro de container en mismo network
2. **Debuggear**: Por quÃ© Orchestrator container no arranca
3. **Verificar**: Networking entre containers
4. **Configurar**: Ray Client API correctamente
5. **Documentar**: Setup completo cuando funcione

**Prioridad**: Baja (sistema ya validado sin esto)  
**Esfuerzo estimado**: 2-4 horas de debugging networking  
**Beneficio**: Marginal (ya tenemos 4 niveles de testing)

---

## ğŸ“ DecisiÃ³n

**APLAZAMOS Ray en containers.**

**RazÃ³n**: 
- Sistema 100% validado con estrategia actual
- Ray + vLLM funcionando en Kubernetes (producciÃ³n real)
- E2E containers funcionan con MockAgents
- Tiempo mejor invertido en features nuevas

**Cuando retomar**: 
- Si necesitamos CI/CD sin Kubernetes
- Si queremos testing mÃ¡s aislado
- Si tenemos tiempo libre para optimizar setup

---

**Creado**: 2025-10-11  
**Estado**: InvestigaciÃ³n pendiente (no bloqueante)  
**Prioridad**: Baja

