# TODO: Refactor VLLMAgentJobBase - Separar Variantes

**Fecha**: 2025-10-11  
**Prioridad**: Media  
**Estado**: Pendiente

---

## üéØ Problema Actual

`VLLMAgentJobBase` tiene una dependencia condicional de Ray que causa problemas en CI:

**Problema adicional descubierto**: Hay un directorio `tests/ray/` que crea un namespace package
que entra en conflicto con el m√≥dulo `ray` real, causando:
```
AttributeError: <module 'ray' (namespace) from ['/home/runner/.../tests/ray']> 
                does not have the attribute 'init'
```

**Soluci√≥n temporal aplicada**: 
- Skip de `test_deliberate_async_usecase.py` cuando Ray no est√° disponible
- Verificaci√≥n de `hasattr(ray, 'remote')` antes de usar Ray

```python
# Actual implementaci√≥n
try:
    import ray
    RAY_AVAILABLE = True
except ImportError:
    RAY_AVAILABLE = False
    ray = None

# Despu√©s...
if RAY_AVAILABLE:
    @ray.remote(num_cpus=1, max_restarts=2)
    class VLLMAgentJob(VLLMAgentJobBase):
        pass
else:
    class VLLMAgentJob(VLLMAgentJobBase):  # Fallback
        pass
```

**Problemas**:
1. L√≥gica condicional compleja
2. Diferentes comportamientos seg√∫n si Ray est√° disponible
3. Confusi√≥n sobre cu√°ndo usar cada variante
4. Tests dif√≠ciles de mantener

---

## üí° Soluci√≥n Propuesta

### Opci√≥n A: Dos Clases Separadas (RECOMENDADO)

Crear dos implementaciones expl√≠citas:

```python
# 1. Base class (sin Ray)
class VLLMAgentBase:
    """Base implementation for vLLM agents (no Ray dependency)."""
    
    def __init__(self, agent_id, role, vllm_url, model, ...):
        self.agent_id = agent_id
        self.role = role
        # ...
    
    async def execute(self, task_id, task, constraints, diversity):
        """Execute agent and return result."""
        # Implementation
        pass

# 2. Ray Actor (con Ray)
@ray.remote(num_cpus=1, max_restarts=2)
class VLLMAgentJob(VLLMAgentBase):
    """Ray remote actor for distributed execution."""
    
    def __init__(self, agent_id, role, vllm_url, model, nats_url, ...):
        super().__init__(agent_id, role, vllm_url, model, ...)
        self.nats_url = nats_url
        # Ray-specific setup
    
    async def run_async(self, task_id, task, constraints, diversity):
        """Execute and publish to NATS."""
        result = await self.execute(task_id, task, constraints, diversity)
        await self._publish_to_nats(result)
        return result
```

**Beneficios**:
- ‚úÖ Separaci√≥n clara de responsabilidades
- ‚úÖ Tests m√°s simples (VLLMAgentBase sin Ray)
- ‚úÖ Ray opcional solo para producci√≥n
- ‚úÖ M√°s f√°cil de mantener

---

## üìÅ Estructura Propuesta

```
src/swe_ai_fleet/orchestrator/
‚îú‚îÄ‚îÄ agents/
‚îÇ   ‚îú‚îÄ‚îÄ vllm_agent_base.py        # Base implementation (no Ray)
‚îÇ   ‚îî‚îÄ‚îÄ vllm_agent_ray.py         # Ray actor wrapper
‚îî‚îÄ‚îÄ ray_jobs/
    ‚îî‚îÄ‚îÄ __init__.py               # Re-exports

tests/unit/
‚îú‚îÄ‚îÄ test_vllm_agent_base_unit.py  # Tests sin Ray
‚îî‚îÄ‚îÄ ray_jobs/
    ‚îî‚îÄ‚îÄ test_vllm_agent_job_unit.py  # Tests con Ray (skipped si no disponible)
```

---

## üîÑ Plan de Migraci√≥n

### Fase 1: Crear `VLLMAgentBase` (sin Ray)
1. Mover l√≥gica core a nueva clase base
2. Sin dependencia de NATS
3. Solo l√≥gica de vLLM API
4. Tests unitarios completos

### Fase 2: Refactorizar `VLLMAgentJob` (con Ray)
1. Heredar de `VLLMAgentBase`
2. A√±adir l√≥gica de NATS
3. Decorador `@ray.remote` siempre aplicado
4. Import condicional del m√≥dulo completo

### Fase 3: Actualizar Tests
1. Tests de `VLLMAgentBase`: Sin Ray, sin NATS
2. Tests de `VLLMAgentJob`: Con Ray (skipped si no disponible)
3. Tests de integraci√≥n: Con vLLM real (opcional)

### Fase 4: Actualizar Use Cases
1. `DeliberateAsync`: Usar `VLLMAgentJob.remote()`
2. Tests: Usar `VLLMAgentBase` directamente
3. Documentaci√≥n actualizada

---

## üéØ C√≥digo Ejemplo

### vllm_agent_base.py
```python
"""Base vLLM agent implementation (no external dependencies)."""
import asyncio
import aiohttp
from typing import Any, Dict

class VLLMAgentBase:
    """Base implementation for vLLM agents."""
    
    def __init__(
        self,
        agent_id: str,
        role: str,
        vllm_url: str,
        model: str,
        temperature: float = 0.7,
        max_tokens: int = 2000,
    ):
        self.agent_id = agent_id
        self.role = role
        self.vllm_url = vllm_url
        self.model = model
        self.temperature = temperature
        self.max_tokens = max_tokens
    
    async def generate_proposal(
        self,
        task: str,
        constraints: Dict[str, Any],
        diversity: bool = False
    ) -> Dict[str, Any]:
        """Generate proposal using vLLM API."""
        # Current implementation from VLLMAgentJobBase
        pass
    
    def _build_prompt(self, task: str, constraints: Dict[str, Any]) -> str:
        """Build prompt for vLLM."""
        pass
```

### vllm_agent_ray.py
```python
"""Ray actor wrapper for VLLMAgentBase."""
try:
    import ray
    from .vllm_agent_base import VLLMAgentBase
    
    @ray.remote(num_cpus=1, max_restarts=2)
    class VLLMAgentJob(VLLMAgentBase):
        """Ray remote actor for distributed vLLM execution."""
        
        def __init__(self, nats_url: str, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.nats_url = nats_url
            self.nc = None  # NATS connection
        
        async def run_async(
            self,
            task_id: str,
            task: str,
            constraints: Dict[str, Any],
            diversity: bool = False
        ):
            """Execute and publish result to NATS."""
            result = await self.generate_proposal(task, constraints, diversity)
            await self._publish_to_nats(task_id, result)
            return result
        
        async def _publish_to_nats(self, task_id: str, result: Dict[str, Any]):
            """Publish result to NATS."""
            pass

except ImportError:
    # Ray not available
    VLLMAgentJob = None
```

---

## üìä Impacto

### Tests
- **Antes**: 3 tests fallando en CI (sin Ray)
- **Despu√©s**: Todos los tests pasando (VLLMAgentBase testeable sin Ray)

### Complejidad
- **Antes**: L√≥gica condicional en imports y decoradores
- **Despu√©s**: Dos clases claras y separadas

### Mantenibilidad
- **Antes**: Confuso cu√°ndo usar cada variante
- **Despu√©s**: Claro: Base para tests, Job para producci√≥n

---

## ‚úÖ Checklist de Implementaci√≥n

- [ ] Crear `vllm_agent_base.py` con l√≥gica core
- [ ] Mover tests a `test_vllm_agent_base_unit.py`
- [ ] Crear `vllm_agent_ray.py` con Ray actor
- [ ] Actualizar `DeliberateAsync` para usar nueva estructura
- [ ] Actualizar tests de integraci√≥n
- [ ] Actualizar documentaci√≥n
- [ ] Verificar CI pasa sin Ray
- [ ] Verificar producci√≥n funciona con Ray

---

## üîó Referencias

- Archivo actual: `src/swe_ai_fleet/orchestrator/ray_jobs/vllm_agent_job.py`
- Tests: `tests/unit/ray_jobs/test_vllm_agent_job_unit.py`
- Use case: `src/swe_ai_fleet/orchestrator/usecases/deliberate_async_usecase.py`
- Issue CI: AttributeError: module 'ray' has no attribute 'remote'

---

## üí≠ Notas

- La soluci√≥n actual (condicional) funciona pero es temporal
- Refactor mejorar√° la testabilidad y claridad
- No es urgente (workaround funciona)
- Prioridad media - cuando tengamos tiempo

---

**Creado**: 2025-10-11  
**Para revisar**: 2025-10-12  
**Estimaci√≥n**: 2-3 horas de trabajo

