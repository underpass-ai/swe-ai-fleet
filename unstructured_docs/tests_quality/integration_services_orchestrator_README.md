# Orchestrator Service E2E Tests

E2E tests for the Orchestrator Service using real infrastructure (NATS, Redis, Orchestrator Service) in containers.

## ğŸ¯ What These Tests Cover

### Test Files
- **`test_deliberate_e2e.py`** (7 tests) - Multi-agent deliberation
- **`test_orchestrate_e2e.py`** (8 tests) - Complete task workflow
- **`test_realistic_workflows_e2e.py`** (5 tests) - Real-world scenarios

### Main RPC Endpoints
1. âœ… **Deliberate** - Multi-agent peer review and consensus
2. âœ… **Orchestrate** - Complete task execution workflow
3. âœ… **CreateCouncil** - Council management
4. âœ… **GetStatus** - Health and observability

### Realistic Scenarios
- âœ… Complete task lifecycle (Planning â†’ Deliberation â†’ Selection â†’ Execution)
- âœ… Multi-phase story workflow (ARCHITECT â†’ DEV â†’ QA â†’ DEVOPS)
- âœ… Parallel task orchestration (3 tasks simultaneously)
- âœ… Complex consensus building (multi-round deliberation)
- âœ… Council management and reuse

---

## ğŸ“‹ Prerequisites

### 1. Container Runtime
**Podman** (Docker is paid software - not used in this project)

```bash
# Check Podman
podman --version
```

### 2. podman-compose
```bash
# Install
pip install podman-compose

# Verify
podman-compose --version
```

---

## ğŸš€ Running E2E Tests

### Quick Start

```bash
# From project root
./tests/integration/services/orchestrator/run-e2e.sh
```

This script:
1. Builds test and service images
2. Starts NATS, Redis, Orchestrator Service
3. Waits for all services to be healthy
4. Runs all E2E tests
5. Cleans up containers

### Manual Execution

```bash
# Start infrastructure
podman-compose -f tests/integration/services/orchestrator/docker-compose.e2e.yml up -d

# Wait for services (30-60 seconds)
sleep 60

# Run tests
podman-compose -f tests/integration/services/orchestrator/docker-compose.e2e.yml run --rm tests

# Cleanup
podman-compose -f tests/integration/services/orchestrator/docker-compose.e2e.yml down -v
```

---

## ğŸ—ï¸ Infrastructure

### Services Started

| Service | Image | Port (Host) | Port (Container) |
|---------|-------|-------------|------------------|
| **NATS** | `nats:2.10-alpine` | 24222 | 4222 |
| **Redis** | `redis:7-alpine` | 26379 | 6379 |
| **Orchestrator** | Local build | 50055 | 50055 |

**Note**: Different ports than Context Service to avoid conflicts.

### Healthchecks

All services have healthchecks before tests run:
- **NATS**: Monitoring endpoint (`/healthz`)
- **Redis**: `PING` command
- **Orchestrator**: gRPC channel ready check

---

## ğŸ§ª Test Structure

```
tests/integration/services/orchestrator/
â”œâ”€â”€ conftest.py                      # Fixtures
â”œâ”€â”€ docker-compose.e2e.yml          # Infrastructure definition
â”œâ”€â”€ Dockerfile.test                 # Test container
â”œâ”€â”€ run-e2e.sh                      # Execution script
â”œâ”€â”€ requirements-test.txt           # Test dependencies
â”œâ”€â”€ test_deliberate_e2e.py          # Deliberate endpoint tests
â”œâ”€â”€ test_orchestrate_e2e.py         # Orchestrate endpoint tests
â”œâ”€â”€ test_realistic_workflows_e2e.py # Realistic scenarios
â””â”€â”€ README.md                       # This file
```

---

## ğŸ“Š Test Coverage

### Deliberate Endpoint (7 tests)
- âœ… Basic deliberation
- âœ… Multiple rounds
- âœ… Different roles
- âœ… With constraints
- âœ… Error handling (empty task, invalid role)
- âœ… Convergence and consensus

### Orchestrate Endpoint (8 tests)
- âœ… Basic orchestration
- âœ… With context integration
- âœ… Different roles
- âœ… With constraints
- âœ… Error handling
- âœ… Winner selection quality
- âœ… All agents contribution

### Realistic Workflows (5 tests)
- âœ… Complete task lifecycle
- âœ… Multi-phase story workflow (4 roles)
- âœ… Parallel task orchestration (3 tasks)
- âœ… Quality improvement with rounds
- âœ… Council management

**Total: 20 E2E tests**

---

## ğŸ¯ What These Tests Validate

### 1. Multi-Agent Coordination
- âœ… Multiple agents participate in deliberation
- âœ… All agents contribute proposals
- âœ… No race conditions in parallel execution
- âœ… Unique agent IDs maintained

### 2. Consensus Building
- âœ… Winner is selected based on scoring
- âœ… All candidates are evaluated
- âœ… Best proposal wins
- âœ… Metadata is tracked

### 3. Role-Based Routing
- âœ… Different roles (DEV, QA, ARCHITECT, DEVOPS, DATA)
- âœ… Role-specific councils
- âœ… Correct role handling

### 4. Complete Workflows
- âœ… Planning â†’ Orchestration â†’ Selection
- âœ… Multi-phase stories (ARCHITECT â†’ DEV â†’ QA â†’ DEVOPS)
- âœ… No data loss between phases
- âœ… Execution IDs tracked

### 5. Error Handling
- âœ… Empty task descriptions
- âœ… Invalid roles
- âœ… Missing parameters
- âœ… Graceful degradation

---

## ğŸ”§ Environment Variables

Tests use these environment variables when running in containers:

| Variable | Default | Description |
|----------|---------|-------------|
| `ORCHESTRATOR_HOST` | `localhost` | Orchestrator service hostname |
| `REDIS_HOST` | `localhost` | Redis hostname |
| `NATS_HOST` | `localhost` | NATS hostname |

---

## ğŸ“ˆ Performance

**Typical execution times:**
- Infrastructure startup: 30-60 seconds (first run)
- Infrastructure startup: 10-20 seconds (cached images)
- Per test: 200ms - 2s (depending on deliberation rounds)
- **Total test suite: ~30-60 seconds**

---

## ğŸ“ Best Practices

### âœ… DO
- Use fixtures for service clients (`orchestrator_stub`)
- Generate unique test IDs (`test_task_id` fixture)
- Verify response structure AND semantics
- Test error conditions
- Test parallel execution

### âŒ DON'T
- Hardcode task IDs (use fixtures)
- Skip error handling tests
- Make tests dependent on execution order
- Commit generated `*_pb2.py` files

---

## ğŸš€ Next Steps

### Planned Enhancements
1. **NATS Event Verification** - Verify `orchestrator.events` published
2. **Context Service Integration** - E2E with real Context Service
3. **Performance Benchmarks** - Deliberation latency SLAs
4. **Chaos Testing** - NATS/Redis failures mid-orchestration
5. **Load Testing** - 100+ concurrent orchestrations

---

**Status**: ğŸš§ In Development  
**Target Quality**: â­â­â­â­â­ 9/10 (matching Context Service)  
**Methodology**: Replicated from Context Service success

