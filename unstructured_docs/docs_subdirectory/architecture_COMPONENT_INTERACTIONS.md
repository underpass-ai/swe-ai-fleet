# SWE AI Fleet - Component Interactions & Communication Flows

**Last Updated**: October 14, 2025
**Status**: ğŸŸ¢ Active - Reflects current implementation

---

## ğŸ¯ Executive Summary

This document describes **how components communicate** in the SWE AI Fleet system, including:
- Synchronous communication (gRPC)
- Asynchronous messaging (NATS JetStream)
- Distributed execution (Ray)
- Tool execution within workspace containers

---

## ğŸ“Š System Components

### Deployed Services

| Service | Port | Language | Status | Purpose |
|---------|------|----------|--------|---------|
| **Planning** | 50051 | Go | âœ… Running | FSM-based story lifecycle management |
| **StoryCoach** | 50052 | Go | âœ… Running | Story quality scoring (INVEST) |
| **Workspace** | 50053 | Go | âœ… Running | Workspace result validation & scoring |
| **Context** | 50054 | Python | âœ… Running | Context hydration & management |
| **Orchestrator** | 50055 | Python | âœ… Running | Multi-agent deliberation & coordination |
| **UI (PO React)** | 80 | React | âœ… Running | Product Owner interface |
| **Gateway** | 8080 | Go | ğŸš§ Planned | REST API + SSE bridge (future) |

### Infrastructure

| Component | Port | Purpose |
|-----------|------|---------|
| **NATS JetStream** | 4222 | Async event bus |
| **Redis/Valkey** | 6379 | Short-term cache & planning data |
| **Neo4j** | 7687 | Decision graph & long-term memory |
| **Ray Cluster** | 10001 | Distributed agent execution |
| **vLLM Server** | 8000 | LLM inference engine |

---

## ğŸ”„ Communication Patterns

### 1. **Synchronous Communication (gRPC)**

**When**: Real-time operations, request-response needed immediately

**Pattern**:
```
Client â†’ gRPC Call â†’ Server â†’ Response â†’ Client
        (protobuf)            (protobuf)
```

**Examples**:

#### Gateway â†’ Orchestrator
```python
# Gateway calls Orchestrator
orchestrator_stub = OrchestratorServiceStub(channel)
response = orchestrator_stub.Orchestrate(
    OrchestrateRequest(
        task_id="task-001",
        role="DEV",
        task_description="Add hello_world() function",
        constraints=TaskConstraints(...)
    )
)
# Returns: winner, candidates, duration_ms
```

#### Orchestrator â†’ Context
```python
# Orchestrator gets hydrated context
context_stub = ContextServiceStub(channel)
response = context_stub.GetContext(
    GetContextRequest(
        story_id="US-123",
        role="DEV",
        phase="BUILD",
        token_budget=4096
    )
)
# Returns: context text, token_count, scopes
```

**Service Communication Map**:
```
Gateway â†’ Orchestrator:50055
Gateway â†’ Context:50054
Gateway â†’ Planning:50051
Gateway â†’ StoryCoach:50052

Orchestrator â†’ Context:50054
Orchestrator â†’ Planning:50051 (future)

Context â†’ Neo4j:7687
Context â†’ Redis:6379
```

---

### 2. **Asynchronous Messaging (NATS JetStream)**

**When**: Event-driven workflows, decoupled communication, guaranteed delivery

**Pattern**:
```
Publisher â†’ NATS Stream â†’ Durable Consumer â†’ Handler
           (fire-forget)    (queue group)     (async)
```

**Streams Configured**:

| Stream | Subjects | Retention | Purpose |
|--------|----------|-----------|---------|
| **PLANNING_EVENTS** | `planning.>` | 30d | Story/plan lifecycle events |
| **CONTEXT** | `context.>` | 7d | Context updates & decisions |
| **ORCHESTRATOR_EVENTS** | `orchestration.>` | 7d | Deliberation & task dispatch |
| **AGENT_RESULTS** | `agent.results.>` | 1h | Agent execution results (Ray) |

**Key Subjects**:
```
planning.story.transitioned      # Story moved to new phase
planning.plan.approved           # Plan approved by PO

context.updated                  # Context changed (decisions, etc)

orchestration.deliberation.completed    # Agents deliberated, decision made
orchestration.task.dispatched          # Task sent to agent

agent.results.{task_id}          # Agent completed task (from Ray)
```

---

### 3. **Distributed Execution (Ray)**

**When**: Parallel agent execution, GPU workloads, async deliberation

**Pattern**:
```
Orchestrator â†’ Ray.remote() â†’ Ray Cluster â†’ N Parallel Jobs â†’ NATS Results
```

**Flow**:

```python
# 1. Orchestrator submits Ray jobs
class DeliberateAsync:
    def execute(self, task_id, task, role, num_agents=3):
        # Create N Ray actors
        for i in range(num_agents):
            agent_actor = VLLMAgentJob.remote(
                agent_id=f"agent-{role}-{i}",
                vllm_url="http://vllm-server:8000",
                model="Qwen/Qwen3-0.6B",
                nats_url="nats://nats:4222"
            )

            # Submit job (non-blocking)
            job_ref = agent_actor.run.remote(
                task_id=task_id,
                task_description=task,
                constraints=constraints
            )

        # Return immediately (don't wait)
        return {"task_id": task_id, "status": "PENDING"}

# 2. Ray executes in parallel
Ray Cluster:
  â”œâ”€â†’ Agent 1 â†’ vLLM:8000 â†’ generate() â†’ NATS publish
  â”œâ”€â†’ Agent 2 â†’ vLLM:8000 â†’ generate() â†’ NATS publish
  â””â”€â†’ Agent 3 â†’ vLLM:8000 â†’ generate() â†’ NATS publish

# 3. Results collected via NATS
DeliberationResultCollector (consumer):
    - Subscribes to: agent.results.{task_id}
    - Collects all N responses
    - Ranks by quality
    - Stores in memory cache

# 4. Client retrieves result
orchestrator_stub.GetDeliberationResult(task_id)
# Returns: status, winner, candidates, duration
```

**Actual Implementation**:
- File: `src/swe_ai_fleet/orchestrator/usecases/deliberate_async_usecase.py`
- Ray Job: `src/swe_ai_fleet/orchestrator/ray_jobs/vllm_agent_job.py`
- Collector: `services/orchestrator/consumers/deliberation_collector.py`

---

## ğŸ”„ Complete Task Execution Flow

### Scenario: "Add hello_world() function to utils.py"

#### **Current Flow (Text Generation Only)**

```
Step 1: Orchestrator receives task
â”œâ”€â†’ gRPC: Orchestrator.Orchestrate(role="DEV", task="Add hello_world()")
â”‚
Step 2: Get context for agent
â”œâ”€â†’ gRPC: Context.GetContext(story_id, role="DEV", phase="BUILD")
â”œâ”€â†’ Returns: hydrated context with story, decisions, subtasks
â”‚
Step 3: Execute deliberation (Ray-based)
â”œâ”€â†’ DeliberateAsync.execute(task_id, task, role, num_agents=3)
â”œâ”€â†’ Creates 3 Ray actors: VLLMAgentJob.remote()
â”œâ”€â†’ Each calls vLLM API: "Generate solution for: {task}"
â”œâ”€â†’ Each publishes to NATS: agent.results.{task_id}
â”‚
Step 4: Collect results
â”œâ”€â†’ DeliberationResultCollector subscribes to agent.results.{task_id}
â”œâ”€â†’ Waits for all 3 responses (with 5min timeout)
â”œâ”€â†’ Ranks by quality score
â”œâ”€â†’ Stores: {status: "COMPLETED", winner: best_response, candidates: []}
â”‚
Step 5: Publish completion
â”œâ”€â†’ NATS: orchestration.deliberation.completed
â”œâ”€â†’ {story_id, task_id, decisions: [...]}
â”‚
Step 6: Update context
â”œâ”€â†’ Context Service consumes event
â”œâ”€â†’ Updates Neo4j with decisions
â”œâ”€â†’ NATS: context.updated
â”‚
Result: TEXT proposal generated, NO actual code changes executed âŒ
```

#### **Target Flow (With Tools - This Session's Goal)**

```
Step 1: Orchestrator receives task
â”œâ”€â†’ gRPC: Orchestrator.ExecuteTaskWithTools(role="DEV", task="Add hello_world()")
â”‚
Step 2: Create workspace container
â”œâ”€â†’ K8s Job created with:
â”‚   â”œâ”€â†’ Git clone of repository
â”‚   â”œâ”€â†’ Tools initialized (GitTool, FileTool, TestTool)
â”‚   â””â”€â†’ Agent with tool access
â”‚
Step 3: Agent executes task WITH tools
â”œâ”€â†’ ToolEnabledAgent.execute(task)
â”œâ”€â†’ Step 3a: LLM plans actions
â”‚   â””â”€â†’ "1. Read file, 2. Add function, 3. Test, 4. Commit"
â”œâ”€â†’ Step 3b: Execute plan using tools
â”‚   â”œâ”€â†’ FileTool.read_file("src/utils.py")
â”‚   â”œâ”€â†’ FileTool.append_file("src/utils.py", new_function)
â”‚   â”œâ”€â†’ TestTool.pytest() â†’ verify no regressions
â”‚   â”œâ”€â†’ GitTool.add(["src/utils.py"])
â”‚   â””â”€â†’ GitTool.commit("feat: add hello_world()")
â”œâ”€â†’ Step 3c: Verify completion
â”‚   â””â”€â†’ Function exists, tests pass, commit created âœ…
â”‚
Step 4: Publish execution result
â”œâ”€â†’ NATS: agent.results.{task_id}
â”œâ”€â†’ {
â”‚     task_id: "task-001",
â”‚     status: "completed",
â”‚     operations: [read, append, pytest, add, commit],
â”‚     audit_trail: [...],
â”‚     artifacts: {
â”‚       commit_sha: "abc123",
â”‚       test_results: "5 passed in 0.3s",
â”‚       files_changed: ["src/utils.py"]
â”‚     }
â”‚   }
â”‚
Step 5: Update context with real changes
â”œâ”€â†’ Context Service consumes event
â”œâ”€â†’ Updates Neo4j: commit info, test results, files changed
â”œâ”€â†’ NATS: context.updated
â”‚
Result: ACTUAL CODE CHANGES made and committed âœ…
```

---

## ğŸ“¡ NATS Event Streams (Detailed)

### Stream: PLANNING_EVENTS

**Subjects**:
```
planning.story.created          # New story created by PO
planning.story.transitioned     # Story moved between phases
planning.plan.approved          # Plan approved, ready for execution
planning.task.created           # Subtask derived from plan
planning.task.assigned          # Task assigned to role
planning.task.completed         # Task marked complete
```

**Publishers**: Planning Service
**Consumers**:
- Context Service (context-planning-events) - Cache invalidation
- Orchestrator Service (orchestrator-planning-events) - Task derivation

**Example Event**:
```json
{
  "subject": "planning.plan.approved",
  "data": {
    "event_type": "PLAN_APPROVED",
    "story_id": "US-123",
    "plan_id": "plan-v2",
    "roles": ["DEV", "QA", "DEVOPS"],
    "subtasks_count": 12,
    "approved_by": "tirso@underpassai.com",
    "timestamp": "2025-10-14T10:30:00Z"
  }
}
```

---

### Stream: ORCHESTRATOR_EVENTS

**Subjects**:
```
orchestration.deliberation.started     # Deliberation begun
orchestration.deliberation.completed   # Agents deliberated, winner selected
orchestration.task.dispatched          # Task sent to agent for execution
orchestration.council.created          # New council formed for role
```

**Publishers**: Orchestrator Service
**Consumers**:
- Context Service (context-orchestration-events) - Decision recording
- Planning Service (planning-orchestration-events) - Task status updates

**Example Event**:
```json
{
  "subject": "orchestration.deliberation.completed",
  "data": {
    "event_type": "DELIBERATION_COMPLETED",
    "story_id": "US-123",
    "task_id": "task-001",
    "role": "DEV",
    "decisions": [
      {
        "id": "dec-001",
        "type": "TECHNICAL_CHOICE",
        "rationale": "Use FastAPI for better async support",
        "alternatives": ["Flask", "Django"],
        "decided_by": "agent-dev-001",
        "affected_subtask": "subtask-api-001"
      }
    ],
    "winner_agent_id": "agent-dev-001",
    "duration_ms": 3500,
    "timestamp": "2025-10-14T10:35:00Z"
  }
}
```

---

### Stream: CONTEXT

**Subjects**:
```
context.updated                 # Context changed (decisions, subtasks, etc)
context.decision.added          # New decision recorded
context.milestone.reached       # Milestone achieved
```

**Publishers**: Context Service
**Consumers**:
- Orchestrator Service (orchestrator-context-updates) - Context awareness
- Gateway Service (gateway-all-events) - SSE to frontend

**Example Event**:
```json
{
  "subject": "context.updated",
  "data": {
    "event_type": "CONTEXT_UPDATED",
    "story_id": "US-123",
    "version": 5,
    "changes": ["decisions", "subtasks"],
    "affected_roles": ["DEV", "QA"],
    "timestamp": "2025-10-14T10:36:00Z"
  }
}
```

---

### Stream: AGENT_RESULTS

**Subjects**:
```
agent.results.{task_id}         # Agent completed task (from Ray jobs)
```

**Publishers**: Ray VLLMAgentJob actors
**Consumers**:
- DeliberationResultCollector - Aggregates multi-agent responses

**Example Event**:
```json
{
  "subject": "agent.results.task-001",
  "data": {
    "agent_id": "agent-dev-001",
    "task_id": "task-001",
    "status": "completed",
    "proposal": {
      "content": "Use FastAPI with async handlers...",
      "confidence": 0.95
    },
    "metadata": {
      "vllm_model": "Qwen/Qwen3-0.6B",
      "tokens_used": 1024,
      "latency_ms": 850
    },
    "timestamp": "2025-10-14T10:34:30Z"
  }
}
```

---

## ğŸŒŠ Complete Workflow Examples

### Workflow 1: Story Creation â†’ Deliberation (Synchronous)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ User/PO â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚ UI Action: Create Story
     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  UI (React) â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ REST: POST /api/stories
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Gateway    â”‚ (Future - TBD)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ gRPC: Planning.CreateStory()
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Planning    â”‚
â”‚   :50051     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Compute DoR score
       â”‚ NATS: planning.story.created
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Service â”‚ (Consumer)
â”‚   :50054        â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Cache story metadata
       â”‚ Ready for context queries
       â†“
     [Story ready for planning]
```

---

### Workflow 2: Plan Approved â†’ Task Execution (Asynchronous)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning     â”‚
â”‚  :50051      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ NATS: planning.plan.approved
       â”‚ {story_id, plan_id, roles: [DEV, QA]}
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OrchestratorPlanningConsumer â”‚
â”‚ (orchestrator-planning-events)â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ [TODO] derive_subtasks(plan_id)
       â”‚ â†’ List[Task]
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TaskQueue    â”‚ [TODO: Implement]
â”‚ (Redis)      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ enqueue(tasks)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Task Dispatcher â”‚ [TODO]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ For each task:
       â”‚   1. Get context
       â”‚   2. Trigger deliberation
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeliberateAsync â”‚
â”‚ (Ray-based)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Creates N Ray jobs
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Ray Cluster  â”‚â”€â”€â”€â”€â†’â”‚ vLLM Server  â”‚
â”‚              â”‚â†â”€â”€â”€â”€â”‚   :8000      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ N agents generate proposals
       â”‚ Each publishes to NATS
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DeliberationResultCollector â”‚
â”‚ (NATS consumer)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Collects N responses
       â”‚ Ranks by quality
       â”‚ NATS: orchestration.deliberation.completed
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OrchestrationEventsConsumer â”‚
â”‚ (Context Service)    â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ ProjectDecisionUseCase.execute()
       â”‚ Updates Neo4j
       â”‚ NATS: context.updated
       â†“
     [Task complete]
```

**Status**: ğŸŸ¡ Partially implemented
- âœ… Ray job submission works
- âœ… NATS event publishing works
- âœ… Context updates work
- âŒ Task derivation not implemented
- âŒ TaskQueue not implemented

---

### Workflow 3: Planning Agent Analyzes Codebase with Tools

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning     â”‚
â”‚  :50051      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ NATS: planning.story.created
       â”‚ {story_id: "US-123", title: "Add authentication"}
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Architect Agent      â”‚
â”‚ (with tools)         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Task: "Analyze codebase for authentication implementation"
       â”‚
       â”‚ Step 1: Clone & analyze structure
       â”œâ”€â†’ GitTool.clone(repo_url)
       â”œâ”€â†’ FileTool.list_files("src/", recursive=True)
       â”‚   Result: Understand project structure
       â”‚
       â”‚ Step 2: Find existing auth code
       â”œâ”€â†’ FileTool.search_in_files("auth|login|session", path="src/")
       â”‚   Result: Found auth patterns in 5 files
       â”‚
       â”‚ Step 3: Read existing implementation
       â”œâ”€â†’ FileTool.read_file("src/auth/middleware.py")
       â”œâ”€â†’ FileTool.read_file("src/models/user.py")
       â”‚   Result: Understand current auth approach
       â”‚
       â”‚ Step 4: Check test coverage
       â”œâ”€â†’ TestTool.pytest(path="tests/auth/", coverage=True)
       â”‚   Result: 60% coverage on auth module
       â”‚
       â”‚ Step 5: Analyze database schema
       â”œâ”€â†’ DatabaseTool.postgresql_query(
       â”‚       "SELECT * FROM information_schema.tables WHERE table_name LIKE '%user%'"
       â”‚   )
       â”‚   Result: 3 user-related tables found
       â”‚
       â”‚ Step 6: Test existing API
       â”œâ”€â†’ HttpTool.get("http://localhost:8080/api/auth/login")
       â”‚   Result: 401 when not authenticated (expected)
       â”‚
       â”‚ Step 7: Check git history
       â”œâ”€â†’ GitTool.log(max_count=50)
       â”œâ”€â†’ GitTool.diff("HEAD~5", "HEAD")
       â”‚   Result: Recent auth changes by team
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Generated Plan       â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Based on ACTUAL codebase analysis:
       â”‚
       â”‚ Subtasks derived:
       â”‚ 1. [DEV] Extend User model with 2FA fields
       â”‚    Dependencies: Current User model uses SQLAlchemy
       â”‚    Files: src/models/user.py, migrations/
       â”‚
       â”‚ 2. [DEV] Implement 2FA token generation
       â”‚    Dependencies: Found pyotp in requirements.txt
       â”‚    Files: src/auth/two_factor.py (new)
       â”‚
       â”‚ 3. [QA] Add 2FA tests (coverage currently 60%)
       â”‚    Dependencies: Existing test pattern in tests/auth/
       â”‚    Files: tests/auth/test_two_factor.py (new)
       â”‚
       â”‚ 4. [DEVOPS] Update Docker image with pyotp
       â”‚    Dependencies: Dockerfile exists at root
       â”‚    Files: Dockerfile, requirements.txt
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Planning     â”‚
â”‚  :50051      â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ NATS: planning.plan.approved
       â”‚ {story_id, plan_id, subtasks: 4}
       â†“
     [Execution phase begins]
```

**Key Benefit**: Plan is based on **ACTUAL** codebase state, not assumptions!

---

### Workflow 4: Agent Executes Task with Tools (Implementation Phase)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Orchestrator â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ gRPC: ExecuteTaskWithTools(role, task)
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workspace Runner   â”‚ [TODO: Implement]
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Creates K8s Job:
       â”‚   - Git clone repo
       â”‚   - Initialize tools
       â”‚   - Execute agent
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent Workspace Container     â”‚
â”‚ (K8s Job Pod)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ /workspace/                   â”‚
â”‚   â”œâ”€â†’ GitTool                â”‚
â”‚   â”œâ”€â†’ FileTool               â”‚
â”‚   â”œâ”€â†’ TestTool               â”‚
â”‚   â”œâ”€â†’ DockerTool             â”‚
â”‚   â”œâ”€â†’ HttpTool               â”‚
â”‚   â””â”€â†’ DatabaseTool           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”‚ Agent workflow:
       â”‚ 1. Read file (FileTool)
       â”‚ 2. Modify code (FileTool)
       â”‚ 3. Run tests (TestTool)
       â”‚ 4. Commit (GitTool)
       â”‚
       â”‚ Audit trail:
       â”‚   â”œâ”€â†’ File: /workspace/.task/audit.log
       â”‚   â”œâ”€â†’ Redis Stream: tool_audit
       â”‚   â””â”€â†’ Neo4j: :ToolExecution nodes
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ NATS         â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ agent.results.{task_id}
       â”‚ {
       â”‚   status: "completed",
       â”‚   operations: [read, append, pytest, commit],
       â”‚   artifacts: {
       â”‚     commit_sha: "abc123",
       â”‚     files_changed: ["src/utils.py"],
       â”‚     tests_passed: true
       â”‚   }
       â”‚ }
       â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Service      â”‚
â”‚ (Consumer)           â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Updates Neo4j:
       â”‚   - Commit info
       â”‚   - Test results
       â”‚   - Tool usage
       â”‚ NATS: context.updated
       â†“
     [Task complete with actual changes] âœ…
```

**Status**: ğŸŸ¡ Partially implemented
- âœ… Tools implemented (git, file, test, docker, http, db)
- âœ… E2E test simulates agent workflow
- âŒ Workspace Runner not implemented
- âŒ K8s Job template not integrated
- âŒ Tool-enabled agent not integrated with Ray

---

## ğŸ—ï¸ Service Dependencies

### Orchestrator Service Dependencies

**Outbound (calls)**:
- Context Service (gRPC) - For GetContext, UpdateContext
- Ray Cluster (Ray API) - For distributed agent execution
- NATS (publish) - For orchestration.* events

**Inbound (called by)**:
- Gateway (gRPC) - For Orchestrate, Deliberate
- NATS consumers - For planning.plan.approved, agent.results.*

**Storage**:
- None directly (stateless) - All state in Context/Planning services

### Context Service Dependencies

**Outbound (calls)**:
- Neo4j (bolt) - For decision graph queries/commands
- Redis/Valkey (redis://) - For planning data cache
- NATS (publish) - For context.* events

**Inbound (called by)**:
- Orchestrator (gRPC) - For GetContext, UpdateContext, RehydrateSession
- NATS consumers - For planning.*, orchestration.* events

**Storage**:
- Neo4j - Decision graph, cases, subtasks, plans
- Redis/Valkey - Cached planning data, timeline

---

## ğŸ”§ Tool Execution Architecture

### Tools Available in Workspace

| Tool | Operations | Purpose | Planning Phase | Implementation Phase |
|------|-----------|---------|----------------|---------------------|
| **GitTool** | 9 ops | clone, status, add, commit, push, pull, checkout, branch, diff, log | âœ… log, diff, status | âœ… add, commit, push |
| **FileTool** | 10 ops | read, write, append, search, list, edit, delete, mkdir, info, diff | âœ… read, search, list, info, diff | âœ… write, edit, append |
| **TestTool** | 5 frameworks | pytest, go test, npm test, cargo test, make test | âœ… Run existing tests | âœ… Run after changes |
| **DockerTool** | 7 ops | build, run, exec, ps, logs, stop, rm | âœ… ps, logs (analyze) | âœ… build, run (deploy) |
| **HttpTool** | 6 methods | GET, POST, PUT, PATCH, DELETE, HEAD | âœ… GET (analyze APIs) | âœ… POST/PUT (test APIs) |
| **DatabaseTool** | 3 DBs | PostgreSQL, Redis, Neo4j queries | âœ… Read schema, query data | âœ… Migrations, updates |

### Tool Usage by Phase

#### ğŸ” **Planning/Analysis Phase** - Tools for Understanding

**Use Cases**:
1. **Codebase Analysis**
   ```python
   # Agent reads existing code to understand patterns
   files = FileTool(workspace)

   # Find all Python files
   py_files = files.list_files("src/", recursive=True, pattern="*.py")

   # Read key files
   for file in important_files:
       content = files.read_file(file)
       # Agent analyzes architecture, patterns, conventions

   # Search for patterns
   results = files.search_in_files("class.*Service", path="src/")
   # Agent understands service structure
   ```

2. **Git History Analysis**
   ```python
   # Understand recent changes
   git = GitTool(workspace)

   # Recent commits
   history = git.log(max_count=50)
   # Agent sees what's been worked on

   # See current branch strategy
   branches = git.branch(list_all=True)

   # Check for uncommitted changes
   status = git.status()
   ```

3. **Test Coverage Analysis**
   ```python
   # Run existing tests to understand coverage
   tests = TestTool(workspace)

   result = tests.pytest(coverage=True, junit_xml="/tmp/results.xml")
   # Agent knows what's tested, what needs tests
   ```

4. **Database Schema Analysis**
   ```python
   # Understand current data model
   db = DatabaseTool()

   # Get PostgreSQL schema
   schema = db.postgresql_query(
       conn_str,
       "SELECT table_name, column_name, data_type FROM information_schema.columns"
   )

   # Check Neo4j graph structure
   nodes = db.neo4j_query(uri, user, pass,
       "MATCH (n) RETURN DISTINCT labels(n), count(n)"
   )
   ```

5. **API Endpoint Analysis**
   ```python
   # Test existing API to understand behavior
   http = HttpTool(allow_localhost=True)

   # Check health endpoint
   health = http.get("http://localhost:8080/health")

   # Get API spec
   spec = http.get("http://localhost:8080/api/openapi.json")
   # Agent understands API structure
   ```

6. **Docker Container Analysis**
   ```python
   # Check running services
   docker = DockerTool(workspace)

   containers = docker.ps(all_containers=True)
   # Agent sees what's deployed

   # Check service logs
   logs = docker.logs("service-name", tail=100)
   # Agent understands errors, warnings
   ```

**Planning Agent Workflow**:
```
1. GitTool.clone() â†’ Get codebase
2. FileTool.list_files() â†’ Understand structure
3. FileTool.search_in_files() â†’ Find relevant code
4. FileTool.read_file() â†’ Analyze implementation
5. TestTool.pytest() â†’ Check test coverage
6. DatabaseTool.query() â†’ Understand data model
7. HttpTool.get() â†’ Test API endpoints

â†’ Agent creates INFORMED plan based on ACTUAL codebase state
```

#### âš™ï¸ **Implementation Phase** - Tools for Execution

**Use Cases**:
1. **Code Changes**
   ```python
   # Implement planned changes
   files.write_file("src/new_module.py", generated_code)
   files.edit_file("src/main.py", search="old", replace="new")
   ```

2. **Test Execution**
   ```python
   # Verify changes don't break existing functionality
   result = tests.pytest(markers="not e2e")
   assert result.success
   ```

3. **Version Control**
   ```python
   # Commit changes
   git.add(["src/new_module.py", "src/main.py"])
   git.commit("feat: implement new feature")
   git.push("origin", "feature/new-feature")
   ```

4. **Deployment**
   ```python
   # Build and test container
   docker.build(tag="myapp:v2.0")
   docker.run(image="myapp:v2.0", ports={"8080": "8080"})

   # Test deployment
   http.get("http://localhost:8080/health")
   ```

**Implementation Agent Workflow**:
```
1. FileTool.read_file() â†’ Understand current code
2. FileTool.write_file() â†’ Make changes
3. TestTool.pytest() â†’ Verify changes
4. FileTool.diff_files() â†’ Review changes
5. GitTool.commit() â†’ Save changes
6. DockerTool.build() â†’ Build image
7. HttpTool.post() â†’ Test API

â†’ Agent EXECUTES plan and VERIFIES results
```

#### ğŸ­ **Tool Usage by Agent Role**

Different agent roles use tools for different purposes:

##### **ARCHITECT Agent** - Analysis & Design
```python
# Analyzes codebase to create informed architecture decisions
tools_used = [
    "FileTool.list_files()",      # Understand structure
    "FileTool.search_in_files()", # Find patterns
    "FileTool.read_file()",       # Read key files
    "GitTool.log()",              # See evolution
    "DatabaseTool.query()",       # Analyze schema
    "HttpTool.get()",             # Test APIs
]

workflow = [
    "1. Analyze current architecture",
    "2. Identify patterns and anti-patterns",
    "3. Design solution aligned with existing code",
    "4. Generate detailed plan with file-level changes"
]
```

##### **DEV Agent** - Implementation
```python
# Implements features and fixes bugs
tools_used = [
    "FileTool.read_file()",      # Understand context
    "FileTool.write_file()",     # Create new code
    "FileTool.edit_file()",      # Modify existing code
    "TestTool.pytest()",         # Verify changes
    "GitTool.add/commit/push()", # Save changes
]

workflow = [
    "1. Read existing code",
    "2. Implement changes",
    "3. Run unit tests",
    "4. Commit working code"
]
```

##### **QA Agent** - Testing & Validation
```python
# Creates tests and validates quality
tools_used = [
    "FileTool.read_file()",      # Read implementation
    "FileTool.write_file()",     # Create test files
    "TestTool.pytest()",         # Run test suites
    "TestTool.go_test()",        # Run Go tests
    "HttpTool.get/post()",       # Integration tests
    "FileTool.diff_files()",     # Review changes
]

workflow = [
    "1. Analyze implementation",
    "2. Create comprehensive tests",
    "3. Run full test suite",
    "4. Validate coverage thresholds"
]
```

##### **DEVOPS Agent** - Deployment & Infrastructure
```python
# Manages deployment and infrastructure
tools_used = [
    "FileTool.read_file()",       # Read Dockerfile, k8s yamls
    "FileTool.edit_file()",       # Update configs
    "DockerTool.build()",         # Build images
    "DockerTool.run()",           # Test locally
    "TestTool.pytest()",          # Run e2e tests
    "HttpTool.get()",             # Health checks
    "DatabaseTool.query()",       # Migration verification
]

workflow = [
    "1. Review current deployment",
    "2. Update Dockerfile/k8s manifests",
    "3. Build and test locally",
    "4. Verify deployment health"
]
```

##### **DATA Agent** - Data & Analytics
```python
# Manages data pipelines and schemas
tools_used = [
    "DatabaseTool.postgresql_query()",  # Schema analysis
    "DatabaseTool.neo4j_query()",       # Graph queries
    "DatabaseTool.redis_command()",     # Cache operations
    "FileTool.read_file()",             # Read migration files
    "FileTool.write_file()",            # Create migrations
    "TestTool.pytest()",                # Data validation tests
]

workflow = [
    "1. Analyze current schema",
    "2. Design migration",
    "3. Create migration files",
    "4. Test with sample data"
]
```

**Cross-Role Collaboration Example**:
```
Story: "Add user profile pictures"

1. ARCHITECT analyzes:
   â”œâ”€â†’ FileTool.search("user", "profile", "upload")
   â”œâ”€â†’ DatabaseTool.query("DESCRIBE users")
   â”œâ”€â†’ HttpTool.get("/api/users/123")
   â””â”€â†’ Decides: Use S3 for storage, add image_url to User model

2. DATA designs schema:
   â”œâ”€â†’ DatabaseTool.query("SHOW COLUMNS FROM users")
   â”œâ”€â†’ FileTool.write_file("migrations/add_profile_image.sql")
   â””â”€â†’ Creates migration script

3. DEV implements:
   â”œâ”€â†’ FileTool.read_file("src/models/user.py")
   â”œâ”€â†’ FileTool.edit_file() â†’ Add image_url field
   â”œâ”€â†’ FileTool.write_file("src/api/upload.py")
   â””â”€â†’ GitTool.commit()

4. QA validates:
   â”œâ”€â†’ FileTool.write_file("tests/test_upload.py")
   â”œâ”€â†’ TestTool.pytest()
   â”œâ”€â†’ HttpTool.post("/api/upload", files=test_image)
   â””â”€â†’ Verifies upload works

5. DEVOPS deploys:
   â”œâ”€â†’ FileTool.edit_file("Dockerfile") â†’ Add image processing libs
   â”œâ”€â†’ DockerTool.build(tag="v2.1.0")
   â”œâ”€â†’ DockerTool.run() â†’ Test locally
   â””â”€â†’ HttpTool.get("http://localhost/health") â†’ Verify

All agents use tools to work with REAL code, not imaginary solutions!
```

### Tool Security Features

**All tools implement**:
- âœ… Workspace isolation - Operations restricted to /workspace
- âœ… Input validation - Prevent path traversal, command injection
- âœ… Timeout protection - Auto-terminate long operations
- âœ… Audit trail - Log to file + Redis + Neo4j
- âœ… Resource limits - File size, result size, request size
- âœ… No credential logging - Passwords/tokens redacted

### Tool Audit Flow

```
Tool Operation
    â†“
AuditLogger.log()
    â”œâ”€â†’ File: /workspace/.task/audit.log (NDJSON)
    â”‚   â””â”€â†’ {"tool": "git", "operation": "commit", "success": true, ...}
    â”‚
    â”œâ”€â†’ Redis Stream: tool_audit
    â”‚   â””â”€â†’ XADD tool_audit * tool git operation commit success true
    â”‚
    â””â”€â†’ Neo4j: (:ToolExecution)
        â””â”€â†’ CREATE (e:ToolExecution {tool, operation, timestamp, ...})
```

**Query audit trail**:
```python
# From file
audit_logger.query_logs(tool="git", success=True, limit=100)

# From Redis
redis.xrange("tool_audit", "-", "+", count=100)

# From Neo4j
MATCH (e:ToolExecution {tool: "git"})
WHERE e.timestamp > timestamp() - 3600000
RETURN e
ORDER BY e.timestamp DESC
LIMIT 100
```

---

## ğŸ¯ Integration Gaps & Roadmap

### Current State (October 2025)

| Component | Status | Notes |
|-----------|--------|-------|
| **Orchestrator gRPC** | âœ… 95% | Deliberate, Orchestrate, GetStatus working |
| **Context gRPC** | âœ… 95% | GetContext, UpdateContext, RehydrateSession working |
| **NATS Consumers** | ğŸŸ¡ 60% | Consume events but don't fully process |
| **Ray Integration** | âœ… 80% | DeliberateAsync works, publishes to NATS |
| **Tools** | âœ… 100% | All 8 tools implemented & tested |
| **Tool-enabled Agents** | âŒ 0% | Not yet integrated |
| **Workspace Runner** | âŒ 0% | Not yet implemented |
| **Task Queue** | âŒ 0% | Not yet implemented |

### Critical Gaps

#### 1. **Task Derivation** (Orchestrator)
**Gap**: Planning publishes `plan.approved`, but Orchestrator doesn't derive subtasks

**Need**:
```python
class OrchestrationUseCase:
    def derive_subtasks(
        self, story_id: str, plan_id: str, roles: list[str]
    ) -> list[Task]:
        """
        Parse plan and extract atomic executable tasks.
        Assign to roles, identify dependencies, set priorities.
        """
```

**Status**: ğŸ”´ Not implemented

#### 2. **Task Queue** (Orchestrator)
**Gap**: No persistent queue for managing task execution order

**Need**:
```python
class TaskQueue:
    def enqueue(self, task: Task, priority: int)
    def dequeue(self) -> Task | None
    def mark_completed(self, task_id: str)
    def get_status(self, task_id: str) -> str
```

**Status**: ğŸ”´ Not implemented (Redis/Valkey backend needed)

#### 3. **Tool-Enabled Agents** (Orchestrator)
**Gap**: Agents generate text but don't execute code using tools

**Need**:
```python
class ToolEnabledAgent(Agent):
    def __init__(self, agent_id, role, workspace_path, tools):
        self.git = GitTool(workspace_path)
        self.files = FileTool(workspace_path)
        self.tests = TestTool(workspace_path)

    def generate(self, task, constraints, diversity=False):
        # 1. LLM generates plan
        plan = self.llm.generate(f"Plan for: {task}")

        # 2. Execute plan using tools
        for step in plan.steps:
            if step.tool == "files.write":
                self.files.write_file(step.path, step.content)
            # ... etc

        # 3. Verify and return results
        return {"success": True, "operations": [...]}
```

**Status**: ğŸ”´ Not implemented (tools ready, needs integration)

#### 4. **Workspace Runner** (Infrastructure)
**Gap**: No component creates K8s Jobs for agent execution

**Need**:
```python
class WorkspaceRunner:
    """
    NATS consumer that:
    1. Subscribes to agent.cmd.execute
    2. Creates K8s Job with workspace container
    3. Job clones repo, initializes tools, runs agent
    4. Publishes results to agent.results.{task_id}
    """
```

**Status**: ğŸ”´ Not implemented (design exists in `workers/workspace_runner.py` skeleton)

---

## ğŸš€ Implementation Phases

### Phase 1: Tools Foundation âœ… COMPLETED (This Session)
- [x] Git, File, Test, Docker, HTTP, Database tools
- [x] Security validators & audit system
- [x] 55 unit tests (100% passing)
- [x] E2E test simulating agent workflow
- [x] Documentation complete

**Deliverable**: Tools ready for agent integration

---

### Phase 2: Tool-Enabled Agent Integration (Next Sprint)

**Goal**: Agent uses tools to execute tasks

**Tasks**:
1. Create `ToolEnabledMockAgent` class
   ```python
   class ToolEnabledMockAgent(Agent):
       def __init__(self, agent_id, role, workspace_path):
           self.tools = {
               "git": GitTool(workspace_path),
               "files": FileTool(workspace_path),
               "tests": TestTool(workspace_path),
           }

       def generate(self, task, constraints, diversity=False):
           # Parse task and use appropriate tools
           if "add function" in task.lower():
               return self._add_function_with_tools(task)
   ```

2. Update `VLLMAgentJob` to accept tools
   ```python
   class VLLMAgentJob(ray.remote):
       def __init__(self, agent_id, role, vllm_url, workspace_path):
           self.agent = ToolEnabledVLLMAgent(
               agent_id, role, vllm_url, workspace_path
           )

       def run(self, task_id, task, constraints):
           # Agent generates plan using LLM
           # Agent executes plan using tools
           # Agent publishes results to NATS
   ```

3. Test E2E: Orchestrator â†’ Ray â†’ Agent with Tools

**Deliverable**: Agent can complete coding tasks using tools

---

### Phase 3: Workspace Runner (Sprint N+2)

**Goal**: Automated K8s Job creation for agent execution

**Tasks**:
1. Implement `WorkspaceRunner` (Python)
   - NATS consumer for `agent.cmd.execute`
   - K8s Job template with tools
   - Result publishing

2. Agent Workspace Container image
   - Base: Python 3.13 + Go + Node
   - Tools pre-installed
   - Non-root user (UID 1000)

3. Test E2E: Planning â†’ Orchestrator â†’ WorkspaceRunner â†’ K8s Job â†’ Results

**Deliverable**: Full async task execution flow

---

### Phase 4: Task Queue & Derivation (Sprint N+3)

**Goal**: Complete task management system

**Tasks**:
1. Implement `TaskQueue` with Redis
2. Implement `derive_subtasks()` in Orchestrator
3. Connect Planning â†’ Orchestrator â†’ TaskQueue
4. Task dependency management

**Deliverable**: Planning-driven task execution

---

### Phase 5: Gateway & SSE (Sprint N+4)

**Goal**: Real-time UI updates

**Tasks**:
1. Implement Gateway service (Go)
2. REST API for UI
3. SSE endpoint for events
4. NATS â†’ SSE bridge

**Deliverable**: Real-time frontend

---

## ğŸ“‹ Service Communication Matrix

| From â†’ To | Protocol | Purpose | Status |
|-----------|----------|---------|--------|
| **Gateway â†’ Orchestrator** | gRPC | Execute tasks | ğŸš§ Gateway TBD |
| **Gateway â†’ Context** | gRPC | Get context | ğŸš§ Gateway TBD |
| **Gateway â†’ Planning** | gRPC | Manage stories | ğŸš§ Gateway TBD |
| **Orchestrator â†’ Context** | gRPC | Get/update context | âœ… Working |
| **Orchestrator â†’ Ray** | Ray API | Distribute jobs | âœ… Working |
| **Planning â†’ NATS** | Pub/Sub | Story events | âœ… Working |
| **Orchestrator â†’ NATS** | Pub/Sub | Orchestration events | âœ… Working |
| **Context â†’ NATS** | Pub/Sub | Context updates | âœ… Working |
| **Ray Jobs â†’ NATS** | Pub/Sub | Agent results | âœ… Working |
| **Context â†’ Neo4j** | Bolt | Graph queries/commands | âœ… Working |
| **Context â†’ Redis** | Redis protocol | Cache operations | âœ… Working |

---

## ğŸ” Monitoring & Debugging

### Health Checks

```bash
# Check all services
kubectl get pods -n swe-ai-fleet

# Orchestrator health
grpcurl -plaintext orchestrator:50055 \
  orchestrator.v1.OrchestratorService/GetStatus

# Context health
grpcurl -plaintext context:50054 \
  fleet.context.v1.ContextService/GetContext
```

### NATS Monitoring

```bash
# Stream stats
nats stream info ORCHESTRATOR_EVENTS

# Consumer lag
nats consumer info ORCHESTRATOR_EVENTS orchestrator-planning-events

# View messages
nats stream view ORCHESTRATOR_EVENTS --last=10
```

### Ray Monitoring

```bash
# Ray dashboard
kubectl port-forward -n swe-ai-fleet svc/ray-head 8265:8265
# Open: http://localhost:8265

# Ray jobs status
ray job list

# Job logs
ray job logs {job_id}
```

---

## ğŸ“– Related Documentation

- [Microservices Architecture](./MICROSERVICES_ARCHITECTURE.md) - Overall system design
- [NATS Consumers Design](./NATS_CONSUMERS_DESIGN.md) - Detailed consumer specs
- [Orchestrator Interactions](../../docs/microservices/ORCHESTRATOR_INTERACTIONS.md) - Orchestrator-specific flows
- [Context Management](./CONTEXT_MANAGEMENT.md) - Context service architecture
- [Deliberate & Orchestrate Design](./DELIBERATE_ORCHESTRATE_DESIGN.md) - Use case integration
- [Tools README](../../src/swe_ai_fleet/tools/README.md) - Agent tools documentation

---

## ğŸ¯ Quick Reference: Current vs Target Architecture

### Current (Implemented)
```
Planning â†’ NATS â†’ Orchestrator â†’ Ray â†’ vLLM â†’ TEXT proposal
                      â†“
                  Context Service â†’ Neo4j
```

### Target (With Tools)
```
Planning â†’ NATS â†’ Orchestrator â†’ WorkspaceRunner â†’ K8s Job
                                                       â†“
                                           Agent + Tools execute CODE
                                                       â†“
                                           NATS â†’ Context â†’ Neo4j
                                                       â†“
                                           Actual changes committed âœ…
```

---

**Document Purpose**: Central reference for understanding how SWE AI Fleet components communicate and coordinate to execute software engineering tasks.

**Audience**: Developers, architects, and contributors need to understand system integration points.

**Status**: Living document - Updated as architecture evolves.

