# ğŸ¯ Arquitectura Simplificada: Containers sin Ray

## Idea

En lugar de usar Ray (complejo), usar **containers simples** que se comuniquen vÃ­a NATS.

---

## ğŸ—ï¸ Arquitectura Propuesta

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Kubernetes / Podman                          â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚             Orchestrator Service                        â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Deliberate(task) â”€â”€> Publica NATS:                    â”‚   â”‚
â”‚  â”‚                       "agent.task.assigned"             â”‚   â”‚
â”‚  â”‚                       {task_id, description, role}      â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  GetDeliberationResult(task_id) â”€â”€> Query Redis/NATS   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                   NATS JetStream                        â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Subjects:                                               â”‚   â”‚
â”‚  â”‚  - agent.task.assigned                                   â”‚   â”‚
â”‚  â”‚  - agent.response.completed                              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         vLLM Agent Workers (Deployment/StatefulSet)     â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Replicas: 3 (o mÃ¡s segÃºn carga)                       â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  Pod 1: â”€â”€â”                                             â”‚   â”‚
â”‚  â”‚  Pod 2: â”€â”€â”¼â”€â”€> Subscribe NATS: agent.task.assigned     â”‚   â”‚
â”‚  â”‚  Pod 3: â”€â”€â”˜    â””â”€> Procesa task                        â”‚   â”‚
â”‚  â”‚                    â””â”€> Llama vLLM                       â”‚   â”‚
â”‚  â”‚                    â””â”€> Publica NATS: agent.response.*  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                           â”‚                                     â”‚
â”‚                           â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 vLLM Server (GPU)                       â”‚   â”‚
â”‚  â”‚                                                          â”‚   â”‚
â”‚  â”‚  HTTP API: /v1/chat/completions                        â”‚   â”‚
â”‚  â”‚  Model: Qwen3-0.6B                                      â”‚   â”‚
â”‚  â”‚  GPU: 1x RTX 3090                                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Flujo Simplificado

### 1. Cliente â†’ Orchestrator
```python
stub.Deliberate(task="Write factorial", role="DEV", num_agents=3)
```

### 2. Orchestrator â†’ NATS (x3 mensajes)
```json
// Message 1
{
  "task_id": "task-123",
  "agent_id": "agent-dev-001",
  "description": "Write factorial",
  "role": "DEV",
  "constraints": {...},
  "diversity": false
}

// Message 2  
{
  "task_id": "task-123",
  "agent_id": "agent-dev-002",
  "description": "Write factorial",
  "role": "DEV",
  "constraints": {...},
  "diversity": true
}

// Message 3
{...}
```

**Subject**: `agent.task.assigned.DEV` (queue group por rol)

### 3. vLLM Agent Workers â†’ Consume NATS
```
Worker Pod 1 â”€â”€> Recibe agent-dev-001 task
               â””â”€> Llama vLLM API
               â””â”€> Publica: agent.response.completed

Worker Pod 2 â”€â”€> Recibe agent-dev-002 task
               â””â”€> Llama vLLM API  
               â””â”€> Publica: agent.response.completed

Worker Pod 3 â”€â”€> Recibe agent-dev-003 task
               â””â”€> Llama vLLM API
               â””â”€> Publica: agent.response.completed
```

### 4. DeliberationResultCollector â†’ Acumula
```
Escucha: agent.response.completed
Acumula por task_id
Cuando 3/3 â”€â”€> Publica: deliberation.completed
```

### 5. Cliente â†’ Consulta
```python
result = stub.GetDeliberationResult(task_id="task-123")
# Retorna las 3 propuestas
```

---

## ğŸ’¡ Ventajas vs Ray

### Simplicidad
- âœ… No necesita Ray cluster
- âœ… Solo containers simples
- âœ… FÃ¡cil de debuggear
- âœ… Menos moving parts

### Escalabilidad
- âœ… Kubernetes Deployment (auto-scaling)
- âœ… HPA basado en queue depth
- âœ… Multiple pods procesando en paralelo

### Compatibilidad
- âœ… Funciona en E2E containers
- âœ… Funciona en K8s
- âœ… Funciona en Podman
- âœ… No requiere Ray operators

---

## ğŸ› ï¸ ImplementaciÃ³n

### vLLM Agent Worker Container

```python
# src/swe_ai_fleet/orchestrator/workers/vllm_agent_worker.py

import asyncio
import json
import nats
import aiohttp


class VLLMAgentWorker:
    """
    Simple worker que consume tasks de NATS y ejecuta con vLLM.
    """
    
    def __init__(self, vllm_url, nats_url, role):
        self.vllm_url = vllm_url
        self.nats_url = nats_url
        self.role = role
    
    async def run(self):
        """Main loop: consume NATS, execute, publish."""
        nc = await nats.connect(self.nats_url)
        js = nc.jetstream()
        
        # Subscribe to tasks for this role (queue group)
        await js.subscribe(
            subject=f"agent.task.assigned.{self.role}",
            queue=f"agent-workers-{self.role}",  # Load balancing
            cb=self._handle_task
        )
        
        print(f"âœ… Worker started for role {self.role}")
        
        # Keep running
        await asyncio.Event().wait()
    
    async def _handle_task(self, msg):
        """Process a task."""
        data = json.loads(msg.data)
        task_id = data["task_id"]
        agent_id = data["agent_id"]
        description = data["description"]
        
        print(f"[{agent_id}] Processing task {task_id}")
        
        # Call vLLM
        proposal = await self._call_vllm(description, data.get("constraints", {}))
        
        # Publish result
        result = {
            "task_id": task_id,
            "agent_id": agent_id,
            "role": self.role,
            "proposal": proposal,
            "status": "completed"
        }
        
        await msg.ack()
        
        nc = await nats.connect(self.nats_url)
        js = nc.jetstream()
        await js.publish("agent.response.completed", json.dumps(result).encode())
        
        print(f"[{agent_id}] âœ… Completed")
    
    async def _call_vllm(self, task, constraints):
        """Call vLLM API."""
        async with aiohttp.ClientSession() as session:
            payload = {
                "model": "Qwen/Qwen3-0.6B",
                "messages": [
                    {"role": "system", "content": f"You are a {self.role} expert"},
                    {"role": "user", "content": task}
                ],
                "temperature": 0.7,
                "max_tokens": 2048
            }
            
            async with session.post(
                f"{self.vllm_url}/v1/chat/completions",
                json=payload
            ) as response:
                data = await response.json()
                return {
                    "content": data["choices"][0]["message"]["content"],
                    "author_id": self.agent_id,
                    "author_role": self.role
                }


if __name__ == "__main__":
    import os
    
    worker = VLLMAgentWorker(
        vllm_url=os.getenv("VLLM_URL", "http://vllm-server-service:8000"),
        nats_url=os.getenv("NATS_URL", "nats://nats:4222"),
        role=os.getenv("AGENT_ROLE", "DEV")
    )
    
    asyncio.run(worker.run())
```

### Kubernetes Deployment

```yaml
# deploy/k8s/vllm-agent-workers.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: vllm-agent-dev
  namespace: swe-ai-fleet
spec:
  replicas: 3  # 3 workers para role DEV
  selector:
    matchLabels:
      app: vllm-agent
      role: dev
  template:
    metadata:
      labels:
        app: vllm-agent
        role: dev
    spec:
      containers:
      - name: agent-worker
        image: registry.underpassai.com/swe-fleet/vllm-agent-worker:v0.1.0
        env:
        - name: AGENT_ROLE
          value: "DEV"
        - name: VLLM_URL
          value: "http://vllm-server-service:8000"
        - name: NATS_URL
          value: "nats://nats:4222"
        resources:
          requests:
            cpu: "500m"
            memory: "512Mi"
          limits:
            cpu: "1"
            memory: "1Gi"

---
# Similar deployments para QA, ARCHITECT, DEVOPS, DATA
```

### ModificaciÃ³n en Orchestrator

```python
# En server.py, mÃ©todo Deliberate:

def Deliberate(self, request, context):
    """EnvÃ­a tasks a NATS para que agents procesen."""
    task_id = str(uuid.uuid4())
    
    # Publicar N tasks a NATS (uno por agent)
    for i in range(request.num_agents or 3):
        agent_id = f"agent-{request.role.lower()}-{i+1:03d}"
        
        task_message = {
            "task_id": task_id,
            "agent_id": agent_id,
            "description": request.task_description,
            "role": request.role,
            "constraints": self._proto_to_dict(request.constraints),
            "diversity": (i > 0),
            "num_agents": request.num_agents or 3
        }
        
        # Publish a NATS
        await self.js.publish(
            subject=f"agent.task.assigned.{request.role}",
            payload=json.dumps(task_message).encode()
        )
    
    # Retornar inmediatamente
    return orchestrator_pb2.DeliberateResponse(
        task_id=task_id,
        # ... resto de campos
    )
```

---

## âœ… Ventajas de esta Arquitectura

### 1. Simplicidad
- âŒ No Ray (no operators, no complejidad)
- âœ… Solo NATS + containers
- âœ… FÃ¡cil de entender y debuggear

### 2. Escalabilidad
- âœ… Kubernetes HPA (auto-scaling)
- âœ… Queue depth metrics para scaling
- âœ… Multiple pods en paralelo

### 3. Fault Tolerance
- âœ… K8s restart policy
- âœ… NATS redelivery si falla
- âœ… Liveness/readiness probes

### 4. Testing
- âœ… Funciona en E2E containers
- âœ… Funciona en K8s
- âœ… FÃ¡cil local testing

---

## ğŸš€ PrÃ³ximos Pasos

Â¿Quieres que implemente esta arquitectura simplificada? SerÃ­a:

1. **Crear `VLLMAgentWorker`** (container simple NATS consumer)
2. **Dockerfile** para el worker
3. **Deployment K8s** para workers (uno por rol)
4. **Modificar Orchestrator** para publicar tasks a NATS
5. **Mantener DeliberationResultCollector** (ya funciona)

**Ventajas**:
- âœ… MÃ¡s simple que Ray
- âœ… Funciona en E2E containers
- âœ… FÃ¡cil de escalar en K8s
- âœ… Compatible con Podman/CRI-O

Â¿Vamos con esta arquitectura? ğŸš€

